# Kimi K2.5（月之暗面 Moonshot AI）

> 调研时间：2026年2月  
> 模型全称：Kimi K2.5（又称 Kimi 2.5）  
> 开发商：月之暗面（Moonshot AI）  
> 前代模型：Kimi K2（2025年7月发布）  
> 发布日期：2026年1月26-27日（静默上线，未举办大型发布会）  
> 开源协议：Modified MIT License（允许商用）

---

## 1. 模型架构与规格

### 核心参数

| 项目 | 规格 |
|------|------|
| 总参数量 | **1 万亿（1T）** |
| 每 token 激活参数 | **320 亿（32B）**，仅 3.2% 被激活 |
| 架构类型 | **Mixture-of-Experts (MoE)** + Transformer |
| Expert 数量 | **384 个**（比 DeepSeek-V3 的 256 个多 50%） |
| 每 token 激活 Expert | **8 个 + 1 个共享 Expert** |
| Expert 隐藏维度 | 2048 |
| 层数 | 61 层（含 1 个 dense layer） |
| 隐藏维度 | 7168 |
| 注意力头数 | 64（为推理效率减半，DeepSeek-V3 为 128） |
| 注意力机制 | **MLA（Multi-head Latent Attention）** |
| 激活函数 | SwiGLU |
| 词表大小 | 160K |
| 稀疏比 | 48x |

### 上下文与输出

| 项目 | 规格 |
|------|------|
| Context Window | **256K tokens**（约 256,000 tokens） |
| 最大输出 tokens | **8,192 tokens** |
| 长文本支持 | 支持超过 100 页文档、整个代码库上传 |

### 多模态能力（K2.5 新增）

- **MoonViT 视觉编码器**：4 亿参数（400M），原生视觉理解
- 训练数据：约 **15 万亿（15T）混合视觉与文本 tokens**（在 K2 基础上继续预训练）
- 支持输入类型：文本、图片、视频、PDF 文档
- 两种模式：**Thinking Mode**（深度推理）和 **Instant Mode**（快速响应）

### 训练创新

- **MuonClip 优化器**：通过 QK-Clip 权重裁剪稳定万亿参数训练，解决 attention logit 爆炸问题
- 在 15.5 万亿 tokens 训练过程中无 loss spike

### K2 vs K2.5 核心区别

| 特性 | K2（2025年7月） | K2.5（2026年1月） |
|------|----------------|------------------|
| 模态 | 纯文本 | 原生多模态（文本+图片+视频） |
| Context Window | 128K | 256K |
| 视觉编码器 | 无 | MoonViT 400M |
| Agent Swarm | 无 | 支持最多 100 个 Agent 并行 |
| 视觉编程 | 不支持 | 截图/录屏生成代码 |
| 适用场景 | 文本写作、编程、调试 | 设计转代码、UI 构建、多模态任务 |

---

## 2. API 定价

### K2.5 API Token 定价（美元）

| 用量类型 | 价格（每百万 tokens） |
|----------|---------------------|
| Input（cache miss） | **$0.60** |
| Input（cache hit） | **$0.10** |
| Output | **$3.00** |

### K2 API Token 定价（美元，对比）

| 用量类型 | 价格（每百万 tokens） |
|----------|---------------------|
| Input（cache miss） | $0.60 |
| Input（cache hit） | $0.15 |
| Output | $2.50 |

### 人民币定价参考（月之暗面官方平台）

2025年4月大幅降价后：

| 模型 | 输入价格 | 输出价格 |
|------|---------|---------|
| kimi-latest-8k | 2 元/百万 tokens（原 12 元） | 10 元/百万 tokens |
| 32k 长文本模型 | 24 元/百万 tokens | — |
| 128k 超长文档模型 | 60 元/百万 tokens | — |

- Cache 创建：4 元/百万 tokens
- Cache 存储：1 元/百万 tokens/分钟
- 图片按 1024 tokens 计入输入量
- 文件处理接口暂免收费

### 订阅计划（Kimi 消费端）

| 计划 | 价格 | 功能 |
|------|------|------|
| Free | $0/月 | 含广告，基础功能，5 credits |
| Starter | $5.99/月 | 无广告，250 次对话/月，30 天历史 |
| Pro | $12.99/月 | 无限历史，600 次对话/月 |
| Premium | $19.99/月 | 1,000 次对话/月 |

### Free Tier 与限制

- 免费 API 额度：约 **150 万 tokens/天**（部分地区，可能变动）
- 支持自托管部署（开源权重）
- API 兼容 OpenAI SDK 格式，base URL：`https://api.moonshot.cn/v1`
- 最大输出 tokens：8,192
- 具体 RPM/TPM 限制需查阅官方平台文档

### 第三方平台可用性

- Together AI
- NVIDIA NIM
- OpenRouter
- OpenCode Zen / Kilocode（部分免费）
- Windsurf（1 credit）

### 与竞品价格对比

| 模型 | Input 价格/百万 tokens | Output 价格/百万 tokens |
|------|----------------------|------------------------|
| Kimi K2.5 | $0.60 | $3.00 |
| Claude Opus 4.5 | ~$25.00 | ~$75.00 |
| GPT-5.2 | ~$15.00 | ~$60.00 |
| Gemini 3 Pro | ~$3.50 | ~$10.50 |

Kimi K2.5 的价格优势极为明显，约为 Claude Opus 4.5 的 **1/40**。

---

## 3. Benchmark 成绩

### 综合 Benchmark 对比表

| Benchmark | 类别 | Kimi K2.5 | GPT-5.2 | Claude Opus 4.5 | Gemini 3 Pro |
|-----------|------|-----------|---------|-----------------|--------------|
| **HLE-Full (w/ tools)** | Agentic/工具 | **50.2** | 45.5 | 43.2 | 45.8 |
| **AIME 2025** | 数学 | 96.1 | **100.0** | 92.8 | 95.0 |
| **HMMT 2025 (Feb)** | 竞赛数学 | 95.4 | **99.4** | 92.9 | 97.3 |
| **IMO-AnswerBench** | 数学推理 | 81.8 | **86.3** | 78.5 | 83.1 |
| **GPQA-Diamond** | 推理 | 87.6 | **92.4** | 87.0 | 91.9 |
| **MMLU-Pro** | 知识 | 87.1 | 86.7 | 89.3 | **90.1** |
| **MMMU-Pro** | 多模态 | 78.5 | 79.5 | 74.0 | **81.0** |
| **SWE-Bench Verified** | 编程（Agentic） | 76.8 | **80.0** | **80.9** | 76.2 |
| **LiveCodeBench v6** | 编程 | **85.0** | — | 82.2 | 87.4 |
| **TerminalBench** | 终端/工具 | 50.8 | 46.2 | **54.0** | 46.4 |
| **OCRBench** | 文档 OCR | **92.3** | 80.7 | 86.5 | 90.3 |
| **OmniDocBench 1.5** | 文档理解 | **88.8** | 85.7 | 84.1 | 87.7 |
| **VideoMMMU** | 视频理解 | 86.6 | 85.9 | 84.4 | **87.6** |
| **MathVision** | 视觉+数学 | 84.2 | 83.0 | 77.1 | **86.1** |
| **HLE** | 综合 | **50.2** | — | — | — |

### K2（前代）Benchmark 成绩

| Benchmark | Kimi K2 | GPT-4.1 |
|-----------|---------|---------|
| SWE-Bench Verified (agentic) | **65.8%** | 54.6% |
| AIME 2024 | 69.6% | — |
| LiveCodeBench v6 | 53.7% | — |
| GPQA-Diamond | 75.1% | — |
| HumanEval Pass@1 | 73.2% | — |
| HumanEval Pass@10 | 89.6% | — |
| MBPP | 76.8% | — |

### K2.5 核心优势领域

1. **Agentic/工具使用**：HLE-Full (w/ tools) 50.2%，超越所有闭源模型
2. **文档理解**：OCRBench 92.3%、OmniDocBench 88.8%，均为最高
3. **编程**：LiveCodeBench v6 85.0%，超越 Claude Opus 4.5
4. **视频理解**：VideoMMMU 86.6%，接近 Gemini 3 Pro

### 排名定位

- LMSYS 竞技场 Coding 榜单：**开源第一、总榜第七**
- 开源模型综合排名：**第二**（Quality Index 46.73，仅次于 GLM-5 Reasoning）
- 国产大模型横评综合评分：**4.1/5.0**（第三，次于 MiniMax M2.5 的 4.7 和 GLM-5 的 4.3）

---

## 4. 核心特性

### Agent Swarm（研究预览）

- 支持最多 **100 个 sub-agent** 并行协作
- 最多 **1,500 次 tool calls**
- 关键步骤缩减 3-4.5 倍，实际运行耗时最多缩短 **4.5 倍**
- 注意：Swarm 模式可能导致成本不可预测地增加

### 视觉编程

- 从 UI 截图直接生成代码
- 从录屏解析动效并自动复现
- 设计稿到代码的像素级还原
- 自主视觉调试：生成代码 → 渲染 → 对比设计稿 → 自动修复

### Thinking Mode

- 默认开启的深度推理模式
- 支持多轮 tool calling + 深度思考结合
- 适用于数学、逻辑、编程等复杂问题
- 可关闭切换为 Instant Mode 获得更快响应

---

## 5. 用户评价与社区反馈

### 正面评价

**编程能力提升（部分用户）**：
- "相比 K2 版本，vibe coding 能力明显提升，更加'听话'，幻觉显著减少" — 80aj.com 实测
- 代码规范性评分 5.0/5.0（掘金国产模型横评）
- 前端审美能力在某些场景超过 Gemini 3 Pro，能精准复刻网页设计
- SWE-bench Verified 76.8%，与 Claude Opus 4.5、GPT-5.2 基本相当

**视觉能力突出**：
- "录屏扒代码、截图改网页！Kimi K2.5 把'视觉×代码'玩明白了" — 智源社区
- 生成的网页具备专业级设计审美和动画效果
- Video to Code 能力出色，从动态视频快速生成高保真前端代码

**性价比极高**：
- Reddit 用户普遍认可其成本优势，价格仅为 GPT/Claude 的几十分之一
- 多个第三方平台提供免费或极低价接入
- 开源权重支持自托管部署

**Agent 能力**：
- 100 个 Agent 并行处理复杂任务，效率提升显著
- Function Calling 和自主决策能力增强

### 负面评价

**编程逻辑不稳定**：
- "写代码太傻了，用了一周评价是不好用" — V2EX 用户（同样的 prompt 其他模型半小时解决，K2.5 花了一下午）
- 实测出现严重逻辑混乱：删除重复标签时意外执行 Git 回滚，导致已完成功能代码全部丢失 — 80aj.com
- 社区普遍认为不如 Gemini 3 Pro/Flash 和 Claude Opus 4.5

**一致性问题**：
- temperature=0 时重复调用结果不可复现，一致性为 **0%**（掘金横评）
- 这是一个严重的工程问题，影响生产环境可靠性

**速度偏慢**：
- 响应时延较长，处理速度不如 MiniMax M2.5 和 GPT 系列
- 多位用户反映等待时间过长

**知识时效性**：
- 在 2024 年诺贝尔物理学奖等时效知识题目上回答错误
- 混淆不同年份的获奖者

**宣传与实际体验落差**：
- 不少用户反映官方宣传效果显著但实际使用体验不如预期
- 评价两极分化严重，因具体使用场景差异较大

### Reddit/社区共识排名（编程能力）

根据 r/ChatGPTCoding 和 r/LocalLLaMA 讨论：

> OpenAI Codex/GPT 系列 > Claude Opus > GLM-5 > **Kimi K2.5** > Minimax M2.5

- K2.5 处于编程能力的"中间层"
- 单次 prompt 表现尚可，但大上下文场景下不如顶级模型
- 视觉编程和 Agent 功能是其差异化优势

### 适用场景建议

| 场景 | 推荐度 | 说明 |
|------|--------|------|
| 前端开发/UI 还原 | ⭐⭐⭐⭐⭐ | 视觉编程是核心优势 |
| 设计稿转代码 | ⭐⭐⭐⭐⭐ | 像素级还原能力突出 |
| 文档理解/OCR | ⭐⭐⭐⭐⭐ | OCRBench 92.3% 最高 |
| 多模态任务 | ⭐⭐⭐⭐ | 原生视觉+文本理解 |
| 后端编程/复杂逻辑 | ⭐⭐⭐ | 逻辑稳定性有待提升 |
| 数学推理 | ⭐⭐⭐⭐ | AIME 96.1%，接近顶级 |
| 生产环境 API | ⭐⭐⭐ | 一致性问题需注意 |
| 预算敏感项目 | ⭐⭐⭐⭐⭐ | 价格优势极大 |

---

## 6. 本地部署要求

- 磁盘空间：约 **600GB**（完整权重）
- 量化版本：约 **240GB**（INT4 量化，推理速度提升 2x）
- 支持 NVIDIA NIM 部署
- GitHub 仓库：[MoonshotAI/Kimi-K2](https://github.com/MoonshotAI/Kimi-K2)

---

## 7. 总结

Kimi K2.5 是月之暗面在 2026 年 1 月推出的万亿参数开源 MoE 多模态模型。其核心竞争力在于：

1. **极致性价比**：API 价格仅为 Claude/GPT 的 1/40
2. **视觉编程**：截图/录屏转代码能力业界领先
3. **Agent Swarm**：100 个 Agent 并行，复杂任务效率提升 4.5x
4. **文档理解**：OCR 和文档处理 benchmark 最高分

主要短板在于编程逻辑稳定性、输出一致性和响应速度。社区评价两极分化，视觉和 Agent 场景获得好评，但纯编程任务仍落后于 Claude 和 GPT 系列。对于预算敏感且侧重前端/视觉开发的团队，K2.5 是一个极具竞争力的选择。
