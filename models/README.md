<h1 align="center">ğŸ¤– AI Models for Vibe Coding</h1>

<p align="center">
  <b>Models we actually use â€” pricing, specs, benchmarks, and real-world feedback</b><br>
  <sub>Covering Anthropic, OpenAI, Google, Zhipu, Moonshot, MiniMax</sub>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Claude-Opus_%7C_Sonnet-CC785C?logo=anthropic" alt="Claude"/>
  <img src="https://img.shields.io/badge/GPT-5.3_Codex-412991?logo=openai" alt="GPT"/>
  <img src="https://img.shields.io/badge/Gemini-3_Pro_%7C_Flash-4285F4?logo=google" alt="Gemini"/>
  <img src="https://img.shields.io/badge/GLM--5-Zhipu-00B4D8" alt="GLM-5"/>
  <img src="https://img.shields.io/badge/Kimi-K2.5-FF6B6B" alt="Kimi"/>
  <img src="https://img.shields.io/badge/MiniMax-M2.5-FFD700" alt="MiniMax"/>
</p>

---

<!-- ============================================================ -->
<!-- ENGLISH -->
<!-- ============================================================ -->

<details open>
<summary><h2>API Pricing</h2></summary>

| Model | Input ($/1M) | Output ($/1M) | Cache Write | Cache Read/Hit | Batch Input | Batch Output | Long Context | Notes |
|:------|:------------:|:-------------:|:-----------:|:--------------:|:-----------:|:------------:|:------------:|:------|
| **Claude Opus 4.6** | $5.00 | $25.00 | 5min: $6.25, 1h: $10.00 | $0.50 | $2.50 | $12.50 | >200K: $10/$37.50 | Fast Mode: $30/$150 |
| **Claude Sonnet 4.6** | $3.00 | $15.00 | 5min: $3.75, 1h: $6.00 | $0.30 | $1.50 | $7.50 | >200K: $6/$22.50 | â€” |
| **Claude Opus 4.5** | $5.00 | $25.00 | â€” | $0.50 | $2.50 | $12.50 | â€” | 67% cheaper than Opus 4.1 |
| **Claude Sonnet 4.5** | $3.00 | $15.00 | $3.75 | $0.30 | $1.50 | $7.50 | >200K: $6/$22.50 | â€” |
| **GPT-5.3 Codex** | $1.75 | $14.00 | â€” | Cached: $0.175 | â€” | â€” | â€” | Reasoning tokens billed as output |
| **GPT-5.3 Codex Spark** | â€” | â€” | â€” | â€” | â€” | â€” | â€” | Research Preview, no API pricing |
| **Gemini 3 Pro** | $2.00 | $12.00 | â€” | $0.20â€“0.40 | $1.00 | $6.00 | >200K: $4/$18 | Cache storage: $4.50/1M/hr |
| **Gemini 3 Flash** | $0.50 | $3.00 | â€” | $0.05 | â€” | â€” | â€” | Audio input: $1.00 |
| **GLM-5** | $1.00 | $3.20 | â€” | â€” | â€” | â€” | â€” | MIT open-source, self-deploy |
| **Kimi K2.5** | $0.60 | $3.00 | â€” | $0.10 | â€” | â€” | â€” | ~1/40 of Claude pricing |
| **MiniMax M2.5** | $0.30 | $1.10 | â€” | $0.15 | â€” | â€” | â€” | ~1/10â€“1/20 of Opus 4.6 |

> **Tip:** All prices are per 1 million tokens. "Cache Write" and "Cache Read/Hit" refer to prompt caching features. "Long Context" shows surcharges for inputs exceeding 200K tokens (format: input/output). Batch pricing applies to asynchronous batch API calls.

</details>

<!-- ============================================================ -->
<!-- CHINESE -->
<!-- ============================================================ -->

<details>
<summary><h2>API å®šä»·</h2></summary>

| æ¨¡å‹ | è¾“å…¥ ($/1M) | è¾“å‡º ($/1M) | Cache å†™å…¥ | Cache è¯»å– | Batch è¾“å…¥ | Batch è¾“å‡º | é•¿ä¸Šä¸‹æ–‡åŠ ä»· | å¤‡æ³¨ |
|:-----|:-----------:|:-----------:|:----------:|:----------:|:----------:|:----------:|:------------:|:-----|
| **Claude Opus 4.6** | $5.00 | $25.00 | 5min: $6.25, 1h: $10.00 | $0.50 | $2.50 | $12.50 | >200K: $10/$37.50 | Fast Mode: $30/$150 |
| **Claude Sonnet 4.6** | $3.00 | $15.00 | 5min: $3.75, 1h: $6.00 | $0.30 | $1.50 | $7.50 | >200K: $6/$22.50 | â€” |
| **Claude Opus 4.5** | $5.00 | $25.00 | â€” | $0.50 | $2.50 | $12.50 | â€” | æ¯” Opus 4.1 ä¾¿å®œ 67% |
| **Claude Sonnet 4.5** | $3.00 | $15.00 | $3.75 | $0.30 | $1.50 | $7.50 | >200K: $6/$22.50 | â€” |
| **GPT-5.3 Codex** | $1.75 | $14.00 | â€” | ç¼“å­˜: $0.175 | â€” | â€” | â€” | æ¨ç† token æŒ‰è¾“å‡ºè®¡è´¹ |
| **GPT-5.3 Codex Spark** | â€” | â€” | â€” | â€” | â€” | â€” | â€” | ç ”ç©¶é¢„è§ˆç‰ˆï¼Œæš‚æ—  API å®šä»· |
| **Gemini 3 Pro** | $2.00 | $12.00 | â€” | $0.20â€“0.40 | $1.00 | $6.00 | >200K: $4/$18 | ç¼“å­˜å­˜å‚¨: $4.50/1M/å°æ—¶ |
| **Gemini 3 Flash** | $0.50 | $3.00 | â€” | $0.05 | â€” | â€” | â€” | éŸ³é¢‘è¾“å…¥: $1.00 |
| **GLM-5** | $1.00 | $3.20 | â€” | â€” | â€” | â€” | â€” | MIT å¼€æºï¼Œå¯è‡ªéƒ¨ç½² |
| **Kimi K2.5** | $0.60 | $3.00 | â€” | $0.10 | â€” | â€” | â€” | çº¦ä¸º Claude å®šä»·çš„ 1/40 |
| **MiniMax M2.5** | $0.30 | $1.10 | â€” | $0.15 | â€” | â€” | â€” | çº¦ä¸º Opus 4.6 çš„ 1/10â€“1/20 |

> **æç¤ºï¼š** æ‰€æœ‰ä»·æ ¼å‡ä¸ºæ¯ç™¾ä¸‡ tokenã€‚"Cache å†™å…¥"å’Œ"Cache è¯»å–"æŒ‡æç¤ºç¼“å­˜åŠŸèƒ½ã€‚"é•¿ä¸Šä¸‹æ–‡åŠ ä»·"ä¸ºè¶…è¿‡ 200K token è¾“å…¥æ—¶çš„é™„åŠ è´¹ç”¨ï¼ˆæ ¼å¼ï¼šè¾“å…¥/è¾“å‡ºï¼‰ã€‚Batch å®šä»·é€‚ç”¨äºå¼‚æ­¥æ‰¹é‡ API è°ƒç”¨ã€‚

</details>
<!-- ENGLISH -->

## Subscription Plans & Limits

This section details the subscription tiers, pricing, and request limits for each major AI provider. Plans and pricing are subject to change; refer to each provider's official page for the latest information.

---

### Claude (Anthropic)

| Plan | Price | Opus Access | Limits | Notes |
|------|-------|-------------|--------|-------|
| Free | $0 | âŒ Sonnet only | Limited, resets every 5h | â€” |
| Pro | $20/mo ($17/mo annual) | âœ… Limited | ~45 msgs/5h rolling | Memory, Research, Claude Code |
| Max 5x | $100/mo | âœ… Full, high priority | 5Ã— Pro | Early access to new features |
| Max 20x | $200/mo | âœ… Full, top priority | 20Ã— Pro, zero-latency | â€” |
| Team (Standard) | $25/mo ($20 annual) | âœ… | 5â€“150 users | SSO, admin console |
| Team (Advanced) | $125/mo ($100 annual) | âœ… | 5Ã— Standard | â€” |
| Enterprise | Custom | âœ… | Custom | HIPAA, SCIM, audit logs |

**Key details:**

- **Free** users can only access Sonnet; Opus is not available. Usage is limited and resets on a rolling 5-hour window.
- **Pro** subscribers get limited Opus access with approximately 45 messages per 5-hour rolling window. Includes Memory (persistent context across conversations), Research (deep web research), and Claude Code (CLI-based agentic coding tool).
- **Max 5x** provides 5 times the Pro usage limits with full Opus access at high priority, plus early access to newly released features.
- **Max 20x** provides 20 times the Pro usage limits with top-priority Opus access and zero-latency queuing.
- **Team (Standard)** is designed for small-to-medium teams (5â€“150 users) with SSO and an admin console for user management.
- **Team (Advanced)** offers 5 times the Standard usage limits for teams with heavier workloads.
- **Enterprise** provides custom pricing and limits, with compliance features including HIPAA, SCIM provisioning, and audit logs.

---

### ChatGPT / Codex (OpenAI)

#### ChatGPT Plans

| Plan | Price | Key Features |
|------|-------|--------------|
| Free | $0 | Limited GPT-5.2 |
| Go | $8/mo | Extended GPT-5.2 Instant |
| Plus | $20/mo | Codex agent, advanced reasoning, Sora |
| Pro | $200/mo | Unlimited GPT-5.2, Spark preview, extended Codex |
| Business | $25â€“30/user/mo | Unlimited messages, SAML SSO, 60+ integrations |
| Enterprise | Custom | Extended context, data residency (10 regions), 24/7 support |

**Key details:**

- **Free** users get limited access to GPT-5.2 with lower rate limits and no access to advanced features.
- **Go** is a lightweight tier offering extended access to GPT-5.2 Instant (the faster, lower-latency variant) at a budget-friendly price.
- **Plus** unlocks the Codex agent (cloud-based autonomous coding), advanced reasoning modes, and Sora (video generation).
- **Pro** removes most usage caps on GPT-5.2, provides a preview of Spark (next-generation reasoning), and extends Codex cloud task limits significantly.
- **Business** is per-user pricing for organizations, with unlimited messages, SAML SSO, and 60+ third-party integrations.
- **Enterprise** offers custom pricing with extended context windows, data residency across 10 global regions, and dedicated 24/7 support.

#### Codex Limits (per 5-hour rolling window)

| Plan | Local Messages | Cloud Tasks | Code Reviews/week |
|------|---------------|-------------|-------------------|
| Plus | 45â€“225 | 10â€“60 | 10â€“25 |
| Pro | 300â€“1,500 | 50â€“400 | 100â€“250 |

**Key details:**

- **Local Messages** refer to in-editor Codex interactions (inline completions, chat-based edits).
- **Cloud Tasks** are autonomous background tasks where Codex works on a sandboxed cloud environment (e.g., implementing a feature, fixing a bug across multiple files).
- **Code Reviews/week** is the number of automated pull request reviews Codex can perform per week.
- Limits are expressed as ranges because OpenAI dynamically adjusts them based on system load and demand.

---

### Google AI

#### Consumer Plans

| Plan | Price | Credits | Key Benefits |
|------|-------|---------|--------------|
| Free | $0 | 50/day | Gemini 3 Flash limited |
| AI Plus | $7.99/mo (promo $3.99Ã—2mo) | 200/mo | Gemini 3 Pro, Veo 3, 200GB |
| AI Pro | $19.99/mo (first month free) | 1,000/mo | Higher Pro quota, students free 1yr |
| AI Ultra | $250/mo | â€” | Deep Think, Veo 3 early, Imagen 4, 30TB, YouTube Premium |

**Key details:**

- **Free** users receive 50 credits per day, sufficient for basic Gemini 3 Flash interactions. Access to Pro models is not included.
- **AI Plus** provides 200 credits per month with access to Gemini 3 Pro, Veo 3 (video generation), and 200GB of Google One storage. A promotional price of $3.99/mo is available for the first 2 months.
- **AI Pro** provides 1,000 credits per month with higher Gemini 3 Pro quotas. The first month is free. Students can get AI Pro free for 1 year with a valid .edu email.
- **AI Ultra** is the premium tier with unlimited-style access, including Deep Think (extended reasoning), early access to Veo 3, Imagen 4 (image generation), 30TB of Google One storage, and YouTube Premium included.

#### API Rate Limits

| Tier | RPM | TPM | RPD |
|------|-----|-----|-----|
| Free | 5â€“10 | 250K | 100 |
| Tier 1 | 150â€“300 | 1â€“2M | 1Kâ€“10K |
| Tier 2 | 500â€“2,000 | 2M | 10K+ |

**Key details:**

- **RPM** = Requests Per Minute, **TPM** = Tokens Per Minute, **RPD** = Requests Per Day.
- **Free** API tier is suitable for prototyping and experimentation with very low rate limits.
- **Tier 1** is the standard paid tier, suitable for small-to-medium production workloads.
- **Tier 2** is for high-volume production use cases with significantly higher throughput allowances.
- Tier upgrades are typically automatic based on usage history and billing account standing.

---

### GLM-5 (Zhipu / Z.ai)

| Access Method | Details |
|---------------|---------|
| API Pricing | $1 per 1M input tokens / $3.20 per 1M output tokens |
| chat.z.ai | Free chat interface, no registration required |
| Self-Deploy (HuggingFace) | Full model weights available on HuggingFace under MIT license |
| Self-Deploy (ModelScope) | Full model weights available on ModelScope under MIT license |
| NVIDIA NIM | Free tier available via NVIDIA NIM for optimized inference |

**Key details:**

- GLM-5 is fully open-weight under the MIT license, meaning there are no subscription tiers â€” you can self-host without restrictions.
- The API pricing of $1/$3.20 per 1M tokens (input/output) is competitive and pay-as-you-go with no minimum commitment.
- **chat.z.ai** provides a free, no-registration web chat interface for casual use and evaluation.
- Self-deployment is supported on both HuggingFace and ModelScope, with community-maintained quantized variants available.
- **NVIDIA NIM** offers a free tier for deploying GLM-5 with optimized inference on NVIDIA hardware.

---

### Kimi K2.5 (Moonshot AI)

#### Consumer Plans

| Plan | Price | Limits |
|------|-------|--------|
| Free | $0 | ~1.5M tokens/day (varies by region) |
| Starter | $5.99/mo | 250 conversations/mo |
| Pro | $12.99/mo | 600 conversations/mo |
| Premium | $19.99/mo | 1,000 conversations/mo |

#### API Access

| Access Method | Details |
|---------------|---------|
| Free Tier | ~1.5M tokens/day |
| SDK Compatibility | OpenAI SDK compatible (drop-in replacement) |

**Key details:**

- **Free** users get approximately 1.5 million tokens per day, though the exact limit varies by region and demand.
- **Starter**, **Pro**, and **Premium** plans are conversation-based rather than token-based, making usage more predictable for chat-heavy workflows.
- The API free tier also provides approximately 1.5M tokens/day, suitable for prototyping and light production use.
- Kimi K2.5's API is fully compatible with the OpenAI SDK, allowing developers to switch by changing only the base URL and API key.

---

### MiniMax

| Plan | Details |
|------|---------|
| Pay as You Go | Per-token pricing, no minimum spend or commitment |
| Coding Plan | Developer subscription for M2.5 / M2.1 / M2 model access |
| Audio Subscription | $5â€“$999/mo (tiered by usage volume) |

**Key details:**

- **Pay as You Go** is the default billing model â€” you pay per token consumed with no minimum spend, making it ideal for variable workloads.
- **Coding Plan** is a developer-focused subscription that provides dedicated access to MiniMax's coding-optimized models (M2.5, M2.1, M2) with higher rate limits and priority queuing.
- **Audio Subscription** ranges from $5/mo to $999/mo depending on usage volume, covering text-to-speech, speech-to-text, and voice cloning capabilities.

---

<!-- CHINESE -->

## è®¢é˜…è®¡åˆ’ä¸è¯·æ±‚é™åˆ¶

æœ¬èŠ‚è¯¦ç»†ä»‹ç»å„ä¸»è¦ AI æœåŠ¡å•†çš„è®¢é˜…å±‚çº§ã€å®šä»·å’Œè¯·æ±‚é™åˆ¶ã€‚è®¡åˆ’å’Œå®šä»·å¯èƒ½éšæ—¶å˜åŠ¨ï¼Œè¯·å‚é˜…å„æœåŠ¡å•†å®˜æ–¹é¡µé¢è·å–æœ€æ–°ä¿¡æ¯ã€‚

---

### Claudeï¼ˆAnthropicï¼‰

| è®¡åˆ’ | ä»·æ ¼ | Opus è®¿é—®æƒé™ | é™åˆ¶ | å¤‡æ³¨ |
|------|------|--------------|------|------|
| Freeï¼ˆå…è´¹ç‰ˆï¼‰ | $0 | âŒ ä»…é™ Sonnet | æœ‰é™é¢åº¦ï¼Œæ¯ 5 å°æ—¶é‡ç½® | â€” |
| Pro | $20/æœˆï¼ˆ$17/æœˆï¼ŒæŒ‰å¹´ä»˜è´¹ï¼‰ | âœ… æœ‰é™ | çº¦ 45 æ¡æ¶ˆæ¯/5 å°æ—¶æ»šåŠ¨çª—å£ | Memoryã€Researchã€Claude Code |
| Max 5x | $100/æœˆ | âœ… å®Œæ•´è®¿é—®ï¼Œé«˜ä¼˜å…ˆçº§ | 5 å€ Pro é¢åº¦ | æ–°åŠŸèƒ½æŠ¢å…ˆä½“éªŒ |
| Max 20x | $200/æœˆ | âœ… å®Œæ•´è®¿é—®ï¼Œæœ€é«˜ä¼˜å…ˆçº§ | 20 å€ Pro é¢åº¦ï¼Œé›¶å»¶è¿Ÿ | â€” |
| Teamï¼ˆStandardï¼‰ | $25/æœˆï¼ˆ$20ï¼ŒæŒ‰å¹´ä»˜è´¹ï¼‰ | âœ… | 5â€“150 åç”¨æˆ· | SSOã€ç®¡ç†æ§åˆ¶å° |
| Teamï¼ˆAdvancedï¼‰ | $125/æœˆï¼ˆ$100ï¼ŒæŒ‰å¹´ä»˜è´¹ï¼‰ | âœ… | 5 å€ Standard é¢åº¦ | â€” |
| Enterpriseï¼ˆä¼ä¸šç‰ˆï¼‰ | å®šåˆ¶ä»·æ ¼ | âœ… | å®šåˆ¶é¢åº¦ | HIPAAã€SCIMã€å®¡è®¡æ—¥å¿— |

**è¯¦ç»†è¯´æ˜ï¼š**

- **Freeï¼ˆå…è´¹ç‰ˆï¼‰** ç”¨æˆ·ä»…å¯ä½¿ç”¨ Sonnet æ¨¡å‹ï¼Œæ— æ³•è®¿é—® Opusã€‚ä½¿ç”¨é¢åº¦æœ‰é™ï¼ŒæŒ‰ 5 å°æ—¶æ»šåŠ¨çª—å£é‡ç½®ã€‚
- **Pro** è®¢é˜…è€…å¯æœ‰é™è®¿é—® Opusï¼Œçº¦æ¯ 5 å°æ—¶æ»šåŠ¨çª—å£å†…å¯å‘é€ 45 æ¡æ¶ˆæ¯ã€‚åŒ…å« Memoryï¼ˆè·¨å¯¹è¯æŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰ã€Researchï¼ˆæ·±åº¦ç½‘ç»œç ”ç©¶ï¼‰å’Œ Claude Codeï¼ˆåŸºäºå‘½ä»¤è¡Œçš„æ™ºèƒ½ç¼–ç¨‹å·¥å…·ï¼‰ã€‚
- **Max 5x** æä¾› 5 å€äº Pro çš„ä½¿ç”¨é¢åº¦ï¼Œå®Œæ•´ Opus è®¿é—®æƒé™ä¸”äº«æœ‰é«˜ä¼˜å…ˆçº§ï¼Œå¹¶å¯æŠ¢å…ˆä½“éªŒæ–°å‘å¸ƒçš„åŠŸèƒ½ã€‚
- **Max 20x** æä¾› 20 å€äº Pro çš„ä½¿ç”¨é¢åº¦ï¼Œæœ€é«˜ä¼˜å…ˆçº§ Opus è®¿é—®æƒé™ï¼Œé›¶å»¶è¿Ÿæ’é˜Ÿã€‚
- **Teamï¼ˆStandardï¼‰** é¢å‘ä¸­å°å‹å›¢é˜Ÿï¼ˆ5â€“150 åç”¨æˆ·ï¼‰ï¼Œæä¾› SSO å’Œç®¡ç†æ§åˆ¶å°è¿›è¡Œç”¨æˆ·ç®¡ç†ã€‚
- **Teamï¼ˆAdvancedï¼‰** æä¾› 5 å€äº Standard çš„ä½¿ç”¨é¢åº¦ï¼Œé€‚åˆå·¥ä½œè´Ÿè½½è¾ƒé‡çš„å›¢é˜Ÿã€‚
- **Enterpriseï¼ˆä¼ä¸šç‰ˆï¼‰** æä¾›å®šåˆ¶ä»·æ ¼å’Œé¢åº¦ï¼Œåˆè§„åŠŸèƒ½åŒ…æ‹¬ HIPAAã€SCIM è‡ªåŠ¨é…ç½®å’Œå®¡è®¡æ—¥å¿—ã€‚

---

### ChatGPT / Codexï¼ˆOpenAIï¼‰

#### ChatGPT è®¡åˆ’

| è®¡åˆ’ | ä»·æ ¼ | ä¸»è¦åŠŸèƒ½ |
|------|------|----------|
| Freeï¼ˆå…è´¹ç‰ˆï¼‰ | $0 | æœ‰é™çš„ GPT-5.2 è®¿é—® |
| Go | $8/æœˆ | æ‰©å±•çš„ GPT-5.2 Instant |
| Plus | $20/æœˆ | Codex æ™ºèƒ½ä½“ã€é«˜çº§æ¨ç†ã€Sora |
| Pro | $200/æœˆ | æ— é™ GPT-5.2ã€Spark é¢„è§ˆã€æ‰©å±• Codex |
| Businessï¼ˆå•†ä¸šç‰ˆï¼‰ | $25â€“30/ç”¨æˆ·/æœˆ | æ— é™æ¶ˆæ¯ã€SAML SSOã€60+ é›†æˆ |
| Enterpriseï¼ˆä¼ä¸šç‰ˆï¼‰ | å®šåˆ¶ä»·æ ¼ | æ‰©å±•ä¸Šä¸‹æ–‡ã€æ•°æ®é©»ç•™ï¼ˆ10 ä¸ªåŒºåŸŸï¼‰ã€7Ã—24 æ”¯æŒ |

**è¯¦ç»†è¯´æ˜ï¼š**

- **Freeï¼ˆå…è´¹ç‰ˆï¼‰** ç”¨æˆ·å¯æœ‰é™è®¿é—® GPT-5.2ï¼Œé€Ÿç‡é™åˆ¶è¾ƒä½ï¼Œæ— æ³•ä½¿ç”¨é«˜çº§åŠŸèƒ½ã€‚
- **Go** æ˜¯è½»é‡çº§å±‚çº§ï¼Œä»¥å®æƒ çš„ä»·æ ¼æä¾›æ‰©å±•çš„ GPT-5.2 Instantï¼ˆæ›´å¿«ã€æ›´ä½å»¶è¿Ÿçš„å˜ä½“ï¼‰è®¿é—®ã€‚
- **Plus** è§£é” Codex æ™ºèƒ½ä½“ï¼ˆåŸºäºäº‘çš„è‡ªä¸»ç¼–ç¨‹ï¼‰ã€é«˜çº§æ¨ç†æ¨¡å¼å’Œ Soraï¼ˆè§†é¢‘ç”Ÿæˆï¼‰ã€‚
- **Pro** ç§»é™¤ GPT-5.2 çš„å¤§éƒ¨åˆ†ä½¿ç”¨ä¸Šé™ï¼Œæä¾› Sparkï¼ˆä¸‹ä¸€ä»£æ¨ç†ï¼‰é¢„è§ˆï¼Œå¹¶æ˜¾è‘—æ‰©å±• Codex äº‘ä»»åŠ¡é™åˆ¶ã€‚
- **Businessï¼ˆå•†ä¸šç‰ˆï¼‰** æŒ‰ç”¨æˆ·è®¡è´¹ï¼Œé¢å‘ç»„ç»‡ï¼Œæä¾›æ— é™æ¶ˆæ¯ã€SAML SSO å’Œ 60+ ç¬¬ä¸‰æ–¹é›†æˆã€‚
- **Enterpriseï¼ˆä¼ä¸šç‰ˆï¼‰** æä¾›å®šåˆ¶ä»·æ ¼ï¼Œæ‰©å±•ä¸Šä¸‹æ–‡çª—å£ï¼Œæ”¯æŒ 10 ä¸ªå…¨çƒåŒºåŸŸçš„æ•°æ®é©»ç•™ï¼Œä»¥åŠä¸“å± 7Ã—24 æ”¯æŒã€‚

#### Codex é™åˆ¶ï¼ˆæ¯ 5 å°æ—¶æ»šåŠ¨çª—å£ï¼‰

| è®¡åˆ’ | æœ¬åœ°æ¶ˆæ¯ | äº‘ç«¯ä»»åŠ¡ | ä»£ç å®¡æŸ¥/å‘¨ |
|------|----------|----------|-------------|
| Plus | 45â€“225 | 10â€“60 | 10â€“25 |
| Pro | 300â€“1,500 | 50â€“400 | 100â€“250 |

**è¯¦ç»†è¯´æ˜ï¼š**

- **æœ¬åœ°æ¶ˆæ¯** æŒ‡ç¼–è¾‘å™¨å†…çš„ Codex äº¤äº’ï¼ˆå†…è”è¡¥å…¨ã€åŸºäºèŠå¤©çš„ç¼–è¾‘ï¼‰ã€‚
- **äº‘ç«¯ä»»åŠ¡** æ˜¯ Codex åœ¨æ²™ç›’äº‘ç¯å¢ƒä¸­æ‰§è¡Œçš„è‡ªä¸»åå°ä»»åŠ¡ï¼ˆä¾‹å¦‚å®ç°åŠŸèƒ½ã€è·¨å¤šä¸ªæ–‡ä»¶ä¿®å¤ Bugï¼‰ã€‚
- **ä»£ç å®¡æŸ¥/å‘¨** æ˜¯ Codex æ¯å‘¨å¯æ‰§è¡Œçš„è‡ªåŠ¨ Pull Request å®¡æŸ¥æ•°é‡ã€‚
- é™åˆ¶ä»¥èŒƒå›´å½¢å¼è¡¨ç¤ºï¼Œå› ä¸º OpenAI ä¼šæ ¹æ®ç³»ç»Ÿè´Ÿè½½å’Œéœ€æ±‚åŠ¨æ€è°ƒæ•´ã€‚

---

### Google AI

#### æ¶ˆè´¹è€…è®¡åˆ’

| è®¡åˆ’ | ä»·æ ¼ | ç§¯åˆ† | ä¸»è¦æƒç›Š |
|------|------|------|----------|
| Freeï¼ˆå…è´¹ç‰ˆï¼‰ | $0 | 50/å¤© | Gemini 3 Flash æœ‰é™è®¿é—® |
| AI Plus | $7.99/æœˆï¼ˆä¿ƒé”€ä»· $3.99Ã—2 ä¸ªæœˆï¼‰ | 200/æœˆ | Gemini 3 Proã€Veo 3ã€200GB å­˜å‚¨ |
| AI Pro | $19.99/æœˆï¼ˆé¦–æœˆå…è´¹ï¼‰ | 1,000/æœˆ | æ›´é«˜ Pro é…é¢ï¼Œå­¦ç”Ÿå…è´¹ 1 å¹´ |
| AI Ultra | $250/æœˆ | â€” | Deep Thinkã€Veo 3 æŠ¢å…ˆä½“éªŒã€Imagen 4ã€30TB å­˜å‚¨ã€YouTube Premium |

**è¯¦ç»†è¯´æ˜ï¼š**

- **Freeï¼ˆå…è´¹ç‰ˆï¼‰** ç”¨æˆ·æ¯å¤©è·å¾— 50 ç§¯åˆ†ï¼Œè¶³å¤ŸåŸºæœ¬çš„ Gemini 3 Flash äº¤äº’ä½¿ç”¨ã€‚ä¸åŒ…å« Pro æ¨¡å‹è®¿é—®æƒé™ã€‚
- **AI Plus** æ¯æœˆæä¾› 200 ç§¯åˆ†ï¼Œå¯è®¿é—® Gemini 3 Proã€Veo 3ï¼ˆè§†é¢‘ç”Ÿæˆï¼‰å’Œ 200GB Google One å­˜å‚¨ç©ºé—´ã€‚å‰ 2 ä¸ªæœˆå¯äº«å— $3.99/æœˆçš„ä¿ƒé”€ä»·ã€‚
- **AI Pro** æ¯æœˆæä¾› 1,000 ç§¯åˆ†ï¼ŒGemini 3 Pro é…é¢æ›´é«˜ã€‚é¦–æœˆå…è´¹ã€‚å­¦ç”Ÿå‡­æœ‰æ•ˆ .edu é‚®ç®±å¯å…è´¹ä½¿ç”¨ AI Pro 1 å¹´ã€‚
- **AI Ultra** æ˜¯é«˜çº§å±‚çº§ï¼Œæä¾›æ— é™åˆ¶å¼è®¿é—®ï¼ŒåŒ…æ‹¬ Deep Thinkï¼ˆæ‰©å±•æ¨ç†ï¼‰ã€Veo 3 æŠ¢å…ˆä½“éªŒã€Imagen 4ï¼ˆå›¾åƒç”Ÿæˆï¼‰ã€30TB Google One å­˜å‚¨ç©ºé—´ï¼Œä»¥åŠ YouTube Premiumã€‚

#### API é€Ÿç‡é™åˆ¶

| å±‚çº§ | RPMï¼ˆæ¯åˆ†é’Ÿè¯·æ±‚æ•°ï¼‰ | TPMï¼ˆæ¯åˆ†é’Ÿ Token æ•°ï¼‰ | RPDï¼ˆæ¯æ—¥è¯·æ±‚æ•°ï¼‰ |
|------|---------------------|------------------------|-------------------|
| Freeï¼ˆå…è´¹ï¼‰ | 5â€“10 | 250K | 100 |
| Tier 1 | 150â€“300 | 1â€“2M | 1Kâ€“10K |
| Tier 2 | 500â€“2,000 | 2M | 10K+ |

**è¯¦ç»†è¯´æ˜ï¼š**

- **RPM** = æ¯åˆ†é’Ÿè¯·æ±‚æ•°ï¼Œ**TPM** = æ¯åˆ†é’Ÿ Token æ•°ï¼Œ**RPD** = æ¯æ—¥è¯·æ±‚æ•°ã€‚
- **Freeï¼ˆå…è´¹ï¼‰** API å±‚çº§é€‚åˆåŸå‹å¼€å‘å’Œå®éªŒï¼Œé€Ÿç‡é™åˆ¶éå¸¸ä½ã€‚
- **Tier 1** æ˜¯æ ‡å‡†ä»˜è´¹å±‚çº§ï¼Œé€‚åˆä¸­å°å‹ç”Ÿäº§å·¥ä½œè´Ÿè½½ã€‚
- **Tier 2** é¢å‘é«˜æµé‡ç”Ÿäº§åœºæ™¯ï¼Œååé‡é…é¢æ˜¾è‘—æé«˜ã€‚
- å±‚çº§å‡çº§é€šå¸¸æ ¹æ®ä½¿ç”¨å†å²å’Œè´¦å•è´¦æˆ·çŠ¶æ€è‡ªåŠ¨è¿›è¡Œã€‚

---

### GLM-5ï¼ˆæ™ºè°± / Z.aiï¼‰

| è®¿é—®æ–¹å¼ | è¯¦æƒ… |
|----------|------|
| API å®šä»· | è¾“å…¥ $1 / è¾“å‡º $3.20ï¼ˆæ¯ç™¾ä¸‡ Tokenï¼‰ |
| chat.z.ai | å…è´¹èŠå¤©ç•Œé¢ï¼Œæ— éœ€æ³¨å†Œ |
| è‡ªéƒ¨ç½²ï¼ˆHuggingFaceï¼‰ | å®Œæ•´æ¨¡å‹æƒé‡ï¼ŒMIT è®¸å¯è¯ |
| è‡ªéƒ¨ç½²ï¼ˆModelScopeï¼‰ | å®Œæ•´æ¨¡å‹æƒé‡ï¼ŒMIT è®¸å¯è¯ |
| NVIDIA NIM | å…è´¹å±‚çº§ï¼Œä¼˜åŒ–æ¨ç† |

**è¯¦ç»†è¯´æ˜ï¼š**

- GLM-5 é‡‡ç”¨ MIT è®¸å¯è¯å®Œå…¨å¼€æºå¼€æ”¾æƒé‡ï¼Œæ²¡æœ‰è®¢é˜…å±‚çº§ä¹‹åˆ†â€”â€”æ‚¨å¯ä»¥æ— é™åˆ¶åœ°è‡ªè¡Œéƒ¨ç½²ã€‚
- API å®šä»·ä¸ºè¾“å…¥ $1 / è¾“å‡º $3.20ï¼ˆæ¯ç™¾ä¸‡ Tokenï¼‰ï¼Œå…·æœ‰ç«äº‰åŠ›ï¼ŒæŒ‰é‡ä»˜è´¹ï¼Œæ— æœ€ä½æ¶ˆè´¹ã€‚
- **chat.z.ai** æä¾›å…è´¹ã€æ— éœ€æ³¨å†Œçš„ç½‘é¡µèŠå¤©ç•Œé¢ï¼Œé€‚åˆæ—¥å¸¸ä½¿ç”¨å’Œæ¨¡å‹è¯„ä¼°ã€‚
- æ”¯æŒåœ¨ HuggingFace å’Œ ModelScope ä¸Šè‡ªéƒ¨ç½²ï¼Œç¤¾åŒºç»´æŠ¤çš„é‡åŒ–ç‰ˆæœ¬ä¹Ÿå¯è·å–ã€‚
- **NVIDIA NIM** æä¾›å…è´¹å±‚çº§ï¼Œå¯åœ¨ NVIDIA ç¡¬ä»¶ä¸Šä»¥ä¼˜åŒ–æ¨ç†æ–¹å¼éƒ¨ç½² GLM-5ã€‚

---

### Kimi K2.5ï¼ˆæœˆä¹‹æš—é¢ / Moonshot AIï¼‰

#### æ¶ˆè´¹è€…è®¡åˆ’

| è®¡åˆ’ | ä»·æ ¼ | é™åˆ¶ |
|------|------|------|
| Freeï¼ˆå…è´¹ç‰ˆï¼‰ | $0 | çº¦ 150 ä¸‡ Token/å¤©ï¼ˆå› åœ°åŒºè€Œå¼‚ï¼‰ |
| Starter | $5.99/æœˆ | 250 æ¬¡å¯¹è¯/æœˆ |
| Pro | $12.99/æœˆ | 600 æ¬¡å¯¹è¯/æœˆ |
| Premium | $19.99/æœˆ | 1,000 æ¬¡å¯¹è¯/æœˆ |

#### API è®¿é—®

| è®¿é—®æ–¹å¼ | è¯¦æƒ… |
|----------|------|
| å…è´¹å±‚çº§ | çº¦ 150 ä¸‡ Token/å¤© |
| SDK å…¼å®¹æ€§ | å…¼å®¹ OpenAI SDKï¼ˆå¯ç›´æ¥æ›¿æ¢ï¼‰ |

**è¯¦ç»†è¯´æ˜ï¼š**

- **Freeï¼ˆå…è´¹ç‰ˆï¼‰** ç”¨æˆ·æ¯å¤©å¯è·å¾—çº¦ 150 ä¸‡ Tokenï¼Œä½†å…·ä½“é™åˆ¶å› åœ°åŒºå’Œéœ€æ±‚è€Œå¼‚ã€‚
- **Starter**ã€**Pro** å’Œ **Premium** è®¡åˆ’åŸºäºå¯¹è¯æ¬¡æ•°è€Œé Token æ•°è®¡è´¹ï¼Œä½¿èŠå¤©å¯†é›†å‹å·¥ä½œæµçš„ä½¿ç”¨é‡æ›´å¯é¢„æµ‹ã€‚
- API å…è´¹å±‚çº§åŒæ ·æä¾›çº¦æ¯å¤© 150 ä¸‡ Tokenï¼Œé€‚åˆåŸå‹å¼€å‘å’Œè½»é‡çº§ç”Ÿäº§ä½¿ç”¨ã€‚
- Kimi K2.5 çš„ API å®Œå…¨å…¼å®¹ OpenAI SDKï¼Œå¼€å‘è€…åªéœ€æ›´æ”¹ base URL å’Œ API key å³å¯åˆ‡æ¢ã€‚

---

### MiniMax

| è®¡åˆ’ | è¯¦æƒ… |
|------|------|
| Pay as You Goï¼ˆæŒ‰é‡ä»˜è´¹ï¼‰ | æŒ‰ Token è®¡è´¹ï¼Œæ— æœ€ä½æ¶ˆè´¹æˆ–æ‰¿è¯º |
| Coding Planï¼ˆç¼–ç¨‹è®¡åˆ’ï¼‰ | é¢å‘å¼€å‘è€…çš„è®¢é˜…ï¼Œå¯è®¿é—® M2.5 / M2.1 / M2 æ¨¡å‹ |
| Audio Subscriptionï¼ˆéŸ³é¢‘è®¢é˜…ï¼‰ | $5â€“$999/æœˆï¼ˆæŒ‰ä½¿ç”¨é‡åˆ†å±‚ï¼‰ |

**è¯¦ç»†è¯´æ˜ï¼š**

- **Pay as You Goï¼ˆæŒ‰é‡ä»˜è´¹ï¼‰** æ˜¯é»˜è®¤è®¡è´¹æ¨¡å¼â€”â€”æŒ‰æ¶ˆè€—çš„ Token ä»˜è´¹ï¼Œæ— æœ€ä½æ¶ˆè´¹ï¼Œéå¸¸é€‚åˆå·¥ä½œè´Ÿè½½ä¸ç¨³å®šçš„åœºæ™¯ã€‚
- **Coding Planï¼ˆç¼–ç¨‹è®¡åˆ’ï¼‰** æ˜¯é¢å‘å¼€å‘è€…çš„è®¢é˜…ï¼Œæä¾›å¯¹ MiniMax ç¼–ç¨‹ä¼˜åŒ–æ¨¡å‹ï¼ˆM2.5ã€M2.1ã€M2ï¼‰çš„ä¸“å±è®¿é—®ï¼Œäº«æœ‰æ›´é«˜é€Ÿç‡é™åˆ¶å’Œä¼˜å…ˆæ’é˜Ÿã€‚
- **Audio Subscriptionï¼ˆéŸ³é¢‘è®¢é˜…ï¼‰** æ ¹æ®ä½¿ç”¨é‡ä» $5/æœˆåˆ° $999/æœˆä¸ç­‰ï¼Œæ¶µç›–æ–‡æœ¬è½¬è¯­éŸ³ã€è¯­éŸ³è½¬æ–‡æœ¬å’Œè¯­éŸ³å…‹éš†åŠŸèƒ½ã€‚
<!-- ENGLISH -->

## Model Specifications

| Model | Release | Context | Max Output | Thinking / Reasoning | Multimodal | Architecture | Speed |
|-------|---------|---------|------------|----------------------|------------|--------------|-------|
| Claude Opus 4.6 | 2026-02-05 | 200K (1M beta) | 128K | Adaptive: low/medium/high/max | Text + Image | â€” | â€” |
| Claude Sonnet 4.6 | 2026-02-17 | 200K (1M beta) | 64K | Adaptive + Extended Thinking | Text + Image | â€” | â€” |
| Claude Opus 4.5 | 2025-11-24 | 200K (1M beta) | 64K | Extended Thinking, effort adjustable | Text + Image | â€” | â€” |
| Claude Sonnet 4.5 | 2025-09-29 | 200K (1M beta) | 64K | Extended Thinking | Text + Image | â€” | â€” |
| GPT-5.3 Codex | 2026-02-05 | 400K | 128K | Reasoning effort: low/medium/high | Text + Image | â€” | ~65â€“70 tok/s |
| GPT-5.3 Codex Spark | 2026-02-12 | 128K | â€” | Lightweight reasoning | Text only | Cerebras WSE-3 | 1,000+ tok/s |
| Gemini 3 Pro | 2025-11-18 | 1M | 64K | Dynamic Thinking (LOW/HIGH), always-on | Text + Image + Audio + Video + PDF | MoE Transformer | â€” |
| Gemini 3 Flash | 2025-12-17 | 1M | 64K | Dynamic Thinking (minimal/low/medium/high) | Text + Image + Video + Audio + PDF | â€” | ~218 tok/s |
| GLM-5 | 2026-02-11 | 200K | 128K | Reasoning mode (optional) | Text | 744B MoE (44B active), 256 experts, Ascend 910B | ~17â€“19 tok/s |
| Kimi K2.5 | 2026-01-27 | 256K | 8K | Thinking / Instant dual mode | Text + Image + Video + PDF | 1T MoE (32B active), 384 experts | â€” |
| MiniMax M2.5 | 2026-02-12 | ~205K | Long (w/ CoT) | Reasoning optimized | Text | 230B MoE (10B active) | Standard ~50 tok/s, Lightning ~100 tok/s |

### Key Highlights

- **Gemini 3 Pro / Flash** offer the largest context window at **1M tokens**, with always-on Dynamic Thinking and the broadest multimodal support (text, image, audio, video, PDF).
- **GPT-5.3 Codex Spark** achieves **1,000+ tok/s** inference speed by running on Cerebras WSE-3 wafer-scale hardware â€” an order of magnitude faster than any other model listed.
- **GLM-5** is the only model released under an **MIT open-source license**, built on a 744B MoE architecture running natively on Huawei **Ascend 910B** chips.
- **Kimi K2.5** fields the largest total parameter count at **1 trillion** (32B active) with 384 experts, while keeping its active footprint small for efficient serving.
- **Claude Opus 4.6** leads on max output length at **128K tokens** (tied with GPT-5.3 Codex and GLM-5), paired with a new adaptive thinking system offering four granularity levels.

---

<!-- CHINESE -->

## æ¨¡å‹è§„æ ¼å¯¹æ¯”

| æ¨¡å‹ | å‘å¸ƒæ—¥æœŸ | ä¸Šä¸‹æ–‡çª—å£ | æœ€å¤§è¾“å‡º | æ¨ç†/æ€è€ƒ | å¤šæ¨¡æ€ | æ¶æ„ | é€Ÿåº¦ |
|------|----------|------------|----------|-----------|--------|------|------|
| Claude Opus 4.6 | 2026-02-05 | 200Kï¼ˆ1M å†…æµ‹ï¼‰ | 128K | è‡ªé€‚åº”ï¼šlow/medium/high/max | æ–‡æœ¬ + å›¾åƒ | â€” | â€” |
| Claude Sonnet 4.6 | 2026-02-17 | 200Kï¼ˆ1M å†…æµ‹ï¼‰ | 64K | è‡ªé€‚åº” + æ‰©å±•æ€è€ƒ | æ–‡æœ¬ + å›¾åƒ | â€” | â€” |
| Claude Opus 4.5 | 2025-11-24 | 200Kï¼ˆ1M å†…æµ‹ï¼‰ | 64K | æ‰©å±•æ€è€ƒï¼Œå¯è°ƒèŠ‚æ¨ç†åŠ›åº¦ | æ–‡æœ¬ + å›¾åƒ | â€” | â€” |
| Claude Sonnet 4.5 | 2025-09-29 | 200Kï¼ˆ1M å†…æµ‹ï¼‰ | 64K | æ‰©å±•æ€è€ƒ | æ–‡æœ¬ + å›¾åƒ | â€” | â€” |
| GPT-5.3 Codex | 2026-02-05 | 400K | 128K | æ¨ç†åŠ›åº¦ï¼šlow/medium/high | æ–‡æœ¬ + å›¾åƒ | â€” | ~65â€“70 tok/s |
| GPT-5.3 Codex Spark | 2026-02-12 | 128K | â€” | è½»é‡æ¨ç† | ä»…æ–‡æœ¬ | Cerebras WSE-3 | 1,000+ tok/s |
| Gemini 3 Pro | 2025-11-18 | 1M | 64K | åŠ¨æ€æ€è€ƒï¼ˆLOW/HIGHï¼‰ï¼Œå§‹ç»ˆå¼€å¯ | æ–‡æœ¬ + å›¾åƒ + éŸ³é¢‘ + è§†é¢‘ + PDF | MoE Transformer | â€” |
| Gemini 3 Flash | 2025-12-17 | 1M | 64K | åŠ¨æ€æ€è€ƒï¼ˆminimal/low/medium/highï¼‰ | æ–‡æœ¬ + å›¾åƒ + è§†é¢‘ + éŸ³é¢‘ + PDF | â€” | ~218 tok/s |
| GLM-5 | 2026-02-11 | 200K | 128K | æ¨ç†æ¨¡å¼ï¼ˆå¯é€‰ï¼‰ | æ–‡æœ¬ | 744B MoEï¼ˆ44B æ¿€æ´»ï¼‰ï¼Œ256 ä¸“å®¶ï¼Œæ˜‡è…¾ 910B | ~17â€“19 tok/s |
| Kimi K2.5 | 2026-01-27 | 256K | 8K | æ€è€ƒ/å³æ—¶ åŒæ¨¡å¼ | æ–‡æœ¬ + å›¾åƒ + è§†é¢‘ + PDF | 1T MoEï¼ˆ32B æ¿€æ´»ï¼‰ï¼Œ384 ä¸“å®¶ | â€” |
| MiniMax M2.5 | 2026-02-12 | ~205K | é•¿è¾“å‡ºï¼ˆå« CoTï¼‰ | æ¨ç†ä¼˜åŒ– | æ–‡æœ¬ | 230B MoEï¼ˆ10B æ¿€æ´»ï¼‰ | æ ‡å‡† ~50 tok/sï¼Œé—ªç”µ ~100 tok/s |

### äº®ç‚¹é€Ÿè§ˆ

- **Gemini 3 Pro / Flash** æ‹¥æœ‰æœ€å¤§çš„ **100 ä¸‡ token** ä¸Šä¸‹æ–‡çª—å£ï¼ŒåŠ¨æ€æ€è€ƒå§‹ç»ˆå¼€å¯ï¼Œå¹¶æ”¯æŒæœ€å¹¿æ³›çš„å¤šæ¨¡æ€è¾“å…¥ï¼ˆæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ã€PDFï¼‰ã€‚
- **GPT-5.3 Codex Spark** åŸºäº Cerebras WSE-3 æ™¶åœ†çº§ç¡¬ä»¶ï¼Œæ¨ç†é€Ÿåº¦è¾¾åˆ° **1,000+ tok/s**ï¼Œæ¯”åˆ—è¡¨ä¸­å…¶ä»–æ¨¡å‹å¿«ä¸€ä¸ªæ•°é‡çº§ã€‚
- **GLM-5** æ˜¯å”¯ä¸€ä»¥ **MIT å¼€æºåè®®** å‘å¸ƒçš„æ¨¡å‹ï¼Œé‡‡ç”¨ 744B MoE æ¶æ„ï¼ŒåŸç”Ÿè¿è¡Œäºåä¸º**æ˜‡è…¾ 910B** èŠ¯ç‰‡ã€‚
- **Kimi K2.5** æ€»å‚æ•°é‡è¾¾ **1 ä¸‡äº¿**ï¼ˆ32B æ¿€æ´»ï¼‰ï¼Œæ‹¥æœ‰ 384 ä¸ªä¸“å®¶ï¼Œåœ¨ä¿æŒé«˜æ•ˆæ¨ç†çš„åŒæ—¶å®ç°äº†æœ€å¤§çš„æ¨¡å‹è§„æ¨¡ã€‚
- **Claude Opus 4.6** æœ€å¤§è¾“å‡ºé•¿åº¦è¾¾ **128K token**ï¼ˆä¸ GPT-5.3 Codex å’Œ GLM-5 å¹¶åˆ—ï¼‰ï¼Œå¹¶å¼•å…¥å››æ¡£è‡ªé€‚åº”æ€è€ƒç³»ç»Ÿã€‚
<!-- ENGLISH -->

## Benchmarks

### Coding & Software Engineering

| Benchmark | Opus 4.6 | Sonnet 4.6 | Opus 4.5 | Sonnet 4.5 | GPT-5.3 Codex | Gemini 3 Pro | Gemini 3 Flash | GLM-5 | Kimi 2.5 | MiniMax M2.5 |
|-----------|----------|------------|----------|------------|---------------|-------------|----------------|-------|----------|--------------|
| SWE-bench Verified | 80.8% | 79.6% | **80.9%** | 77.2% | â€” | 76.2% | 78.0% | 77.8% | 76.8% | **80.2%** |
| Terminal-Bench 2.0 | 65.4% | â€” | 59.8% | 50.0% | **77.3%** | 56.2% | â€” | 56.2% | 50.8% | â€” |
| OSWorld | â€” | **72.5%** | 66.3% | 61.4% | 64.7% | â€” | â€” | â€” | â€” | â€” |
| LiveCodeBench | â€” | â€” | â€” | â€” | â€” | â€” | **90.8%** | â€” | 85.0% | â€” |

### Reasoning & Knowledge

| Benchmark | Opus 4.6 | Sonnet 4.6 | GPT-5.3 Codex | Gemini 3 Pro | Gemini 3 Flash | GLM-5 | Kimi 2.5 |
|-----------|----------|------------|---------------|-------------|----------------|-------|----------|
| GPQA Diamond | ~77% | 89.9% | 73.8% | **91.9%** | 90.4% | 68â€“86% | 87.6% |
| MMLU / MMLU-Pro | 85.1% | 89.3% | â€” | **92%** | â€” | â€” | 87.1% |
| ARC-AGI-2 | **68.8%** | 58.3% | â€” | 31â€“45% | 33.6% | â€” | â€” |
| Humanity's Last Exam | 40â€“53% | 33â€“49% | â€” | 38â€“46% | 33.7% | **50.4%** | **50.2%** |
| AIME 2025 | ~94% | â€” | â€” | 95â€“100% | **99.7%** | 88.7% | 96.1% |

### Analysis

On **SWE-bench Verified**, Opus 4.5 (80.9%), Opus 4.6 (80.8%), and MiniMax M2.5 (80.2%) form the top tier at ~80%, while Gemini 3 Flash (78.0%) surprisingly outperforms Gemini 3 Pro (76.2%). **Terminal-Bench 2.0** is dominated by GPT-5.3 Codex at 77.3%, a full 12 points ahead of the next competitor. In **reasoning**, the landscape fragments: Opus 4.6 leads ARC-AGI-2 at 68.8% (nearly doubling its predecessor); Gemini 3 Pro tops GPQA Diamond (91.9%) and MMLU (92%); GLM-5 and Kimi K2.5 share the lead on Humanity's Last Exam (~50%). For **long context**, Opus 4.6 achieves ~76% on MRCR v2 at 1M tokens, while the Gemini 3 series offers 1M context natively across both Pro and Flash.

---

## User Reviews

### Claude Opus 4.6

- ğŸ‘ "Like a senior engineer handling million-line codebase migrations" â€” SentinelOne. ARC-AGI-2 score nearly doubled from 4.5. The 1M context beta fundamentally changes how teams approach large-repo refactors and cross-file reasoning.
- ğŸ‘ Writing quality described as "flatter" than Opus 4.5 â€” less creative prose, more mechanical output. Overconfident behavior: executes destructive actions without confirmation. Pro users report hitting rate limits within 2â€“3 hours of heavy use. An API regression incident on Feb 10â€“11 caused widespread disruption.

### Claude Sonnet 4.6

- ğŸ‘ "Opus 4.5 at Sonnet pricing" â€” Reddit consensus. 70% preferred over Sonnet 4.5 in Claude Code internal testing. OSWorld score of 72.5% is the highest among all models tested.
- ğŸ‘ Complex multi-step tasks still require Opus-tier models. Some developers report higher token consumption in the 4.6 series compared to 4.5, partially offsetting cost savings.

### Claude Opus 4.5

- ğŸ‘ First model to break 80% on SWE-bench Verified. "It just gets it" for architecture patterns and large-scale refactoring â€” Reddit r/ClaudeCode. Token efficiency is best-in-class among frontier models.
- ğŸ‘ Over-autonomous tendencies: rewrites entire architecture without asking, over-documents code with excessive comments. Users report "memory anxiety" as the model approaches thinking token limits, leading to rushed or truncated outputs.

### Claude Sonnet 4.5

- ğŸ‘ Replit reported code edit error rate dropped from 9% to 0% after switching. "Like pairing with a senior engineer" â€” Skywork AI. Strong balance of speed and quality for everyday coding tasks.
- ğŸ‘ "Confidently lies about having read the docs" â€” Reddit r/cursor. Weak long-context retrieval: only 18.5% accuracy at 256K tokens. Many users feel it is "not a huge upgrade" over Sonnet 4, especially for non-coding tasks.

### GPT-5.3 Codex

- ğŸ‘ "Start a task, leave for hours, come back to working software" â€” Matt Shumer. Terminal-Bench #1 at 77.3%. Community consensus: use Opus for planning and architecture, Codex for parallel execution of well-defined tasks.
- ğŸ‘ Silent routing to GPT-5.2 reported by multiple users during peak hours. Spark mode: "rarely logic errors but adds junk code and unnecessary abstractions." One user spent $100 on Opus credits specifically to clean up a Codex-generated dashboard.

### Gemini 3 Pro

- ğŸ‘ Initially hailed as "clearly superior to GPT-5.2 and Opus 4.5" â€” Reddit. GPQA Diamond 91.9% is the highest single-model score. Scaffolding, refactoring, and structured output praised by enterprise users.
- ğŸ‘ Long context quality degrades noticeably after 50K tokens despite 1M window. Rate limits slashed post-launch (RPM âˆ’67%, RPD âˆ’80%). "API frequently becomes unavailable during US business hours." Hallucinations on niche or domain-specific topics remain a concern.

### Gemini 3 Flash

- ğŸ‘ "The Budget Model That Became My Default" â€” popular blog post title. 218 tok/s output speed, 1.7Ã— faster than GPT-5.2. SWE-bench 78.0% beats Gemini 3 Pro (76.2%), a rare case of a smaller model outperforming its larger sibling on agentic coding.
- ğŸ‘ Hallucination rate measured at ~91% on Vectara benchmark. Free-tier quota slashed from 250 to 20 RPD. "Cannot stop outputting code comments" â€” developers report excessive inline documentation that inflates token usage.

### GLM-5

- ğŸ‘ Humanity's Last Exam 50.4% beats GPT-5.2 and Opus 4.5. Hallucination rate of 34% is the industry lowest on Vectara benchmark. "Lightyears better than GLM-4.7" â€” Reddit. Fully MIT open-source with zero NVIDIA dependency (runs on Ascend NPUs).
- ğŸ‘ Slow inference at 17â€“19 tok/s. Agent-mode coding still lags behind closed-source models on complex multi-file tasks. Requires more precise and structured prompts than Claude to achieve best results.

### Kimi K2.5

- ğŸ‘ Visual coding workflow praised â€” screenshot or screencast to working code. OCRBench 92.3% is the highest among all models. Agent Swarm supports up to 100 concurrent agents. Pricing at ~1/40 of Claude makes it accessible for high-volume use.
- ğŸ‘ "Wrote code with it for a week, verdict: not good" â€” V2EX user review. 0% output consistency at temperature=0 (determinism issues). Logic confusion reported: one user's agent accidentally git-rolled back an entire codebase. Inference speed is slow for interactive use.

### MiniMax M2.5

- ğŸ‘ SWE-bench Verified 80.2% â€” SOTA among non-Anthropic models. "Intelligence too cheap to meter" â€” output pricing at $1.10/1M tokens. Lightning mode at 100 tok/s. MiniMax reports 30% of internal company tasks now handled by M2.5.
- ğŸ‘ Hallucination benchmark score of 88% places it at the 36th percentile. Complex coding tasks show inconsistency across runs. Instruction following at 65% (68th percentile) means it occasionally ignores constraints or formatting requirements.

---

## Selection Guide

| Use Case | Recommended Models |
|----------|-------------------|
| Long context + deep reasoning | Claude Opus 4.6 (1M beta), Gemini 3 Pro |
| Coding + agent execution | GPT-5.3 Codex, Claude Opus 4.6, MiniMax M2.5 |
| Cost-effective coding | Gemini 3 Flash, Sonnet 4.6, GLM-5, MiniMax M2.5 |
| Fast iteration / frontend | GPT-5.3 Codex Spark, Kimi K2.5 (visual coding) |
| Open-source / self-deploy | GLM-5, Kimi K2.5, MiniMax M2.5 |
| Document / OCR / multimodal | Kimi K2.5, Gemini 3 series |

## Notes

- Pricing and quotas are subject to change; always check official documentation for the latest information.
- Benchmark scores vary by evaluation setup, including pass@k settings, tool availability, and thinking budget levels.
- User reviews sourced from Reddit, Hacker News, çŸ¥ä¹, V2EX, and æ˜é‡‘ â€” these reflect subjective individual experiences and may not generalize.

---

<!-- CHINESE -->

## åŸºå‡†æµ‹è¯•æ€§èƒ½

### ç¼–ç¨‹ä¸è½¯ä»¶å·¥ç¨‹

| åŸºå‡†æµ‹è¯• | Opus 4.6 | Sonnet 4.6 | Opus 4.5 | Sonnet 4.5 | GPT-5.3 Codex | Gemini 3 Pro | Gemini 3 Flash | GLM-5 | Kimi 2.5 | MiniMax M2.5 |
|---------|----------|------------|----------|------------|---------------|-------------|----------------|-------|----------|--------------|
| SWE-bench Verified | 80.8% | 79.6% | **80.9%** | 77.2% | â€” | 76.2% | 78.0% | 77.8% | 76.8% | **80.2%** |
| Terminal-Bench 2.0 | 65.4% | â€” | 59.8% | 50.0% | **77.3%** | 56.2% | â€” | 56.2% | 50.8% | â€” |
| OSWorld | â€” | **72.5%** | 66.3% | 61.4% | 64.7% | â€” | â€” | â€” | â€” | â€” |
| LiveCodeBench | â€” | â€” | â€” | â€” | â€” | â€” | **90.8%** | â€” | 85.0% | â€” |

### æ¨ç†ä¸çŸ¥è¯†

| åŸºå‡†æµ‹è¯• | Opus 4.6 | Sonnet 4.6 | GPT-5.3 Codex | Gemini 3 Pro | Gemini 3 Flash | GLM-5 | Kimi 2.5 |
|---------|----------|------------|---------------|-------------|----------------|-------|----------|
| GPQA Diamond | ~77% | 89.9% | 73.8% | **91.9%** | 90.4% | 68â€“86% | 87.6% |
| MMLU / MMLU-Pro | 85.1% | 89.3% | â€” | **92%** | â€” | â€” | 87.1% |
| ARC-AGI-2 | **68.8%** | 58.3% | â€” | 31â€“45% | 33.6% | â€” | â€” |
| Humanity's Last Exam | 40â€“53% | 33â€“49% | â€” | 38â€“46% | 33.7% | **50.4%** | **50.2%** |
| AIME 2025 | ~94% | â€” | â€” | 95â€“100% | **99.7%** | 88.7% | 96.1% |

### åˆ†æ

åœ¨ **SWE-bench Verified** ä¸Šï¼ŒOpus 4.5ï¼ˆ80.9%ï¼‰ã€Opus 4.6ï¼ˆ80.8%ï¼‰å’Œ MiniMax M2.5ï¼ˆ80.2%ï¼‰ç»„æˆäº†çº¦ 80% çš„ç¬¬ä¸€æ¢¯é˜Ÿï¼Œè€Œ Gemini 3 Flashï¼ˆ78.0%ï¼‰å‡ºäººæ„æ–™åœ°è¶…è¿‡äº† Gemini 3 Proï¼ˆ76.2%ï¼‰ã€‚**Terminal-Bench 2.0** ç”± GPT-5.3 Codex ä»¥ 77.3% çš„æˆç»©ä¸€éª‘ç»å°˜ï¼Œé¢†å…ˆç¬¬äºŒå 12 ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨**æ¨ç†**æ–¹é¢ï¼Œæ ¼å±€å‘ˆç°ç¢ç‰‡åŒ–ï¼šOpus 4.6 ä»¥ 68.8% é¢†è·‘ ARC-AGI-2ï¼ˆå‡ ä¹æ˜¯å‰ä»£çš„ä¸¤å€ï¼‰ï¼›Gemini 3 Pro åœ¨ GPQA Diamondï¼ˆ91.9%ï¼‰å’Œ MMLUï¼ˆ92%ï¼‰ä¸Šå±…é¦–ï¼›GLM-5 å’Œ Kimi K2.5 åœ¨ Humanity's Last Exam ä¸Šå¹¶åˆ—é¢†å…ˆï¼ˆçº¦ 50%ï¼‰ã€‚åœ¨**é•¿ä¸Šä¸‹æ–‡**æ–¹é¢ï¼ŒOpus 4.6 åœ¨ 1M token çš„ MRCR v2 ä¸Šè¾¾åˆ°çº¦ 76%ï¼Œè€Œ Gemini 3 ç³»åˆ—åœ¨ Pro å’Œ Flash ä¸Šå‡åŸç”Ÿæ”¯æŒ 1M ä¸Šä¸‹æ–‡ã€‚

---

## ç”¨æˆ·è¯„ä»·ä¸ç¤¾åŒºåé¦ˆ

### Claude Opus 4.6

- ğŸ‘ "å°±åƒä¸€ä½èµ„æ·±å·¥ç¨‹å¸ˆåœ¨å¤„ç†ç™¾ä¸‡è¡Œä»£ç åº“çš„è¿ç§»" â€” SentinelOneã€‚ARC-AGI-2 å¾—åˆ†ç›¸æ¯” 4.5 å‡ ä¹ç¿»å€ã€‚1M ä¸Šä¸‹æ–‡ beta ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†å›¢é˜Ÿå¤„ç†å¤§å‹ä»“åº“é‡æ„å’Œè·¨æ–‡ä»¶æ¨ç†çš„æ–¹å¼ã€‚
- ğŸ‘ å†™ä½œè´¨é‡è¢«æè¿°ä¸ºæ¯” Opus 4.5 "æ›´å¹³æ·¡" â€” åˆ›æ„æ€§æ•£æ–‡å‡å°‘ï¼Œè¾“å‡ºæ›´æœºæ¢°åŒ–ã€‚è¿‡åº¦è‡ªä¿¡è¡Œä¸ºï¼šæœªç»ç¡®è®¤å°±æ‰§è¡Œç ´åæ€§æ“ä½œã€‚Pro ç”¨æˆ·åæ˜ åœ¨é«˜å¼ºåº¦ä½¿ç”¨ 2â€“3 å°æ—¶åå°±ä¼šè§¦åŠé€Ÿç‡é™åˆ¶ã€‚2 æœˆ 10â€“11 æ—¥çš„ API å›é€€äº‹ä»¶é€ æˆäº†å¤§èŒƒå›´ä¸­æ–­ã€‚

### Claude Sonnet 4.6

- ğŸ‘ "Sonnet çš„ä»·æ ¼ï¼ŒOpus 4.5 çš„èƒ½åŠ›" â€” Reddit ç¤¾åŒºå…±è¯†ã€‚åœ¨ Claude Code å†…éƒ¨æµ‹è¯•ä¸­ï¼Œ70% çš„ç”¨æˆ·æ›´åå¥½ Sonnet 4.6 è€Œé Sonnet 4.5ã€‚OSWorld å¾—åˆ† 72.5% æ˜¯æ‰€æœ‰æµ‹è¯•æ¨¡å‹ä¸­æœ€é«˜çš„ã€‚
- ğŸ‘ å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ä»ç„¶éœ€è¦ Opus çº§åˆ«çš„æ¨¡å‹ã€‚éƒ¨åˆ†å¼€å‘è€…åæ˜  4.6 ç³»åˆ—çš„ token æ¶ˆè€—é«˜äº 4.5ï¼Œä¸€å®šç¨‹åº¦ä¸ŠæŠµæ¶ˆäº†æˆæœ¬ä¼˜åŠ¿ã€‚

### Claude Opus 4.5

- ğŸ‘ é¦–ä¸ªåœ¨ SWE-bench Verified ä¸Šçªç ´ 80% çš„æ¨¡å‹ã€‚"å®ƒå°±æ˜¯èƒ½ç†è§£" æ¶æ„æ¨¡å¼å’Œå¤§è§„æ¨¡é‡æ„ â€” Reddit r/ClaudeCodeã€‚Token æ•ˆç‡åœ¨å‰æ²¿æ¨¡å‹ä¸­æœ€ä¼˜ã€‚
- ğŸ‘ è¿‡åº¦è‡ªä¸»å€¾å‘ï¼šæœªç»è¯¢é—®å°±é‡å†™æ•´ä½“æ¶æ„ï¼Œè¿‡åº¦æ·»åŠ ä»£ç æ³¨é‡Šå’Œæ–‡æ¡£ã€‚ç”¨æˆ·åæ˜ åœ¨æ¥è¿‘æ€è€ƒ token ä¸Šé™æ—¶å‡ºç°"è®°å¿†ç„¦è™‘"ï¼Œå¯¼è‡´è¾“å‡ºä»“ä¿ƒæˆ–è¢«æˆªæ–­ã€‚

### Claude Sonnet 4.5

- ğŸ‘ Replit æŠ¥å‘Šåˆ‡æ¢åä»£ç ç¼–è¾‘é”™è¯¯ç‡ä» 9% é™è‡³ 0%ã€‚"å°±åƒå’Œä¸€ä½èµ„æ·±å·¥ç¨‹å¸ˆç»“å¯¹ç¼–ç¨‹" â€” Skywork AIã€‚åœ¨æ—¥å¸¸ç¼–ç ä»»åŠ¡ä¸­å®ç°äº†é€Ÿåº¦ä¸è´¨é‡çš„è‰¯å¥½å¹³è¡¡ã€‚
- ğŸ‘ "è‡ªä¿¡åœ°è°ç§°å·²ç»é˜…è¯»äº†æ–‡æ¡£" â€” Reddit r/cursorã€‚é•¿ä¸Šä¸‹æ–‡æ£€ç´¢èƒ½åŠ›å¼±ï¼šåœ¨ 256K token æ—¶å‡†ç¡®ç‡ä»… 18.5%ã€‚è®¸å¤šç”¨æˆ·è®¤ä¸ºç›¸æ¯” Sonnet 4 "æå‡ä¸å¤§"ï¼Œå°¤å…¶æ˜¯åœ¨éç¼–ç ä»»åŠ¡ä¸Šã€‚

### GPT-5.3 Codex

- ğŸ‘ "å¯åŠ¨ä¸€ä¸ªä»»åŠ¡ï¼Œç¦»å¼€å‡ ä¸ªå°æ—¶ï¼Œå›æ¥å°±æ˜¯å¯è¿è¡Œçš„è½¯ä»¶" â€” Matt Shumerã€‚Terminal-Bench ç¬¬ä¸€åï¼Œ77.3%ã€‚ç¤¾åŒºå…±è¯†ï¼šç”¨ Opus åšè§„åˆ’å’Œæ¶æ„è®¾è®¡ï¼Œç”¨ Codex å¹¶è¡Œæ‰§è¡Œå®šä¹‰æ˜ç¡®çš„ä»»åŠ¡ã€‚
- ğŸ‘ å¤šä½ç”¨æˆ·åæ˜ é«˜å³°æœŸè¢«é™é»˜è·¯ç”±åˆ° GPT-5.2ã€‚Spark æ¨¡å¼ï¼š"å¾ˆå°‘æœ‰é€»è¾‘é”™è¯¯ï¼Œä½†ä¼šæ·»åŠ åƒåœ¾ä»£ç å’Œä¸å¿…è¦çš„æŠ½è±¡ã€‚" æœ‰ç”¨æˆ·èŠ±äº† 100 ç¾å…ƒçš„ Opus é¢åº¦ä¸“é—¨æ¸…ç† Codex ç”Ÿæˆçš„ä»ªè¡¨ç›˜ã€‚

### Gemini 3 Pro

- ğŸ‘ æœ€åˆè¢«èª‰ä¸º"æ˜æ˜¾ä¼˜äº GPT-5.2 å’Œ Opus 4.5" â€” Redditã€‚GPQA Diamond 91.9% æ˜¯å•æ¨¡å‹æœ€é«˜åˆ†ã€‚è„šæ‰‹æ¶æ­å»ºã€é‡æ„å’Œç»“æ„åŒ–è¾“å‡ºå—åˆ°ä¼ä¸šç”¨æˆ·å¥½è¯„ã€‚
- ğŸ‘ å°½ç®¡æœ‰ 1M çª—å£ï¼Œé•¿ä¸Šä¸‹æ–‡è´¨é‡åœ¨ 50K token åæ˜æ˜¾ä¸‹é™ã€‚å‘å¸ƒåé€Ÿç‡é™åˆ¶å¤§å¹…å‰Šå‡ï¼ˆRPM âˆ’67%ï¼ŒRPD âˆ’80%ï¼‰ã€‚"API åœ¨ç¾å›½å·¥ä½œæ—¶é—´ç»å¸¸ä¸å¯ç”¨ã€‚" åœ¨å°ä¼—æˆ–é¢†åŸŸç‰¹å®šè¯é¢˜ä¸Šçš„å¹»è§‰é—®é¢˜ä»ç„¶ä»¤äººæ‹…å¿§ã€‚

### Gemini 3 Flash

- ğŸ‘ "æˆä¸ºæˆ‘é»˜è®¤é€‰æ‹©çš„å¹³ä»·æ¨¡å‹" â€” çƒ­é—¨åšæ–‡æ ‡é¢˜ã€‚è¾“å‡ºé€Ÿåº¦ 218 tok/sï¼Œæ¯” GPT-5.2 å¿« 1.7 å€ã€‚SWE-bench 78.0% è¶…è¿‡ Gemini 3 Proï¼ˆ76.2%ï¼‰ï¼Œå°æ¨¡å‹åœ¨æ™ºèƒ½ä½“ç¼–ç ä¸Šå‡»è´¥å¤§æ¨¡å‹çš„ç½•è§æ¡ˆä¾‹ã€‚
- ğŸ‘ Vectara åŸºå‡†æµ‹è¯•å¹»è§‰ç‡çº¦ 91%ã€‚å…è´¹é…é¢ä» 250 RPD å‰Šå‡è‡³ 20 RPDã€‚"åœä¸ä¸‹æ¥åœ°è¾“å‡ºä»£ç æ³¨é‡Š" â€” å¼€å‘è€…åæ˜ è¿‡å¤šçš„è¡Œå†…æ–‡æ¡£å¯¼è‡´ token ç”¨é‡è†¨èƒ€ã€‚

### GLM-5

- ğŸ‘ Humanity's Last Exam 50.4% è¶…è¿‡ GPT-5.2 å’Œ Opus 4.5ã€‚Vectara åŸºå‡†æµ‹è¯•å¹»è§‰ç‡ 34%ï¼Œä¸ºè¡Œä¸šæœ€ä½ã€‚"æ¯” GLM-4.7 å¥½äº†ä¸çŸ¥é“å¤šå°‘ä¸ªé‡çº§" â€” Redditã€‚å®Œå…¨ MIT å¼€æºï¼Œé›¶ NVIDIA ä¾èµ–ï¼ˆå¯åœ¨æ˜‡è…¾ NPU ä¸Šè¿è¡Œï¼‰ã€‚
- ğŸ‘ æ¨ç†é€Ÿåº¦æ…¢ï¼Œä»… 17â€“19 tok/sã€‚æ™ºèƒ½ä½“æ¨¡å¼ç¼–ç åœ¨å¤æ‚å¤šæ–‡ä»¶ä»»åŠ¡ä¸Šä»è½åäºé—­æºæ¨¡å‹ã€‚éœ€è¦æ¯” Claude æ›´ç²¾ç¡®å’Œç»“æ„åŒ–çš„æç¤ºè¯æ‰èƒ½è·å¾—æœ€ä½³æ•ˆæœã€‚

### Kimi K2.5

- ğŸ‘ è§†è§‰ç¼–ç å·¥ä½œæµå¹¿å—å¥½è¯„ â€” æˆªå›¾æˆ–å½•å±å³å¯ç”Ÿæˆå¯è¿è¡Œä»£ç ã€‚OCRBench 92.3% ä¸ºæ‰€æœ‰æ¨¡å‹ä¸­æœ€é«˜ã€‚Agent Swarm æ”¯æŒæœ€å¤š 100 ä¸ªå¹¶å‘æ™ºèƒ½ä½“ã€‚å®šä»·çº¦ä¸º Claude çš„ 1/40ï¼Œé€‚åˆå¤§è§„æ¨¡ä½¿ç”¨ã€‚
- ğŸ‘ "ç”¨å®ƒå†™äº†ä¸€å‘¨ä»£ç ï¼Œç»“è®ºï¼šä¸è¡Œ" â€” V2EX ç”¨æˆ·è¯„ä»·ã€‚temperature=0 æ—¶è¾“å‡ºä¸€è‡´æ€§ä¸º 0%ï¼ˆç¡®å®šæ€§é—®é¢˜ï¼‰ã€‚é€»è¾‘æ··ä¹±ï¼šæœ‰ç”¨æˆ·çš„æ™ºèƒ½ä½“æ„å¤–åœ° git å›æ»šäº†æ•´ä¸ªä»£ç åº“ã€‚äº¤äº’å¼ä½¿ç”¨æ—¶æ¨ç†é€Ÿåº¦åæ…¢ã€‚

### MiniMax M2.5

- ğŸ‘ SWE-bench Verified 80.2% â€” é Anthropic æ¨¡å‹ä¸­çš„ SOTAã€‚"æ™ºèƒ½ä¾¿å®œåˆ°å¯ä»¥å¿½ç•¥ä¸è®¡" â€” è¾“å‡ºå®šä»· $1.10/1M tokensã€‚Lightning æ¨¡å¼ 100 tok/sã€‚MiniMax ç§°å†…éƒ¨ 30% çš„å…¬å¸ä»»åŠ¡ç°å·²ç”± M2.5 å®Œæˆã€‚
- ğŸ‘ å¹»è§‰åŸºå‡†æµ‹è¯•å¾—åˆ† 88%ï¼Œä½äºç¬¬ 36 ç™¾åˆ†ä½ã€‚å¤æ‚ç¼–ç ä»»åŠ¡åœ¨å¤šæ¬¡è¿è¡Œé—´è¡¨ç°ä¸ä¸€è‡´ã€‚æŒ‡ä»¤éµå¾ªç‡ 65%ï¼ˆç¬¬ 68 ç™¾åˆ†ä½ï¼‰ï¼Œæ„å‘³ç€å¶å°”ä¼šå¿½ç•¥çº¦æŸæ¡ä»¶æˆ–æ ¼å¼è¦æ±‚ã€‚

---

## é€‰å‹å»ºè®®

| ä½¿ç”¨åœºæ™¯ | æ¨èæ¨¡å‹ |
|---------|---------|
| é•¿ä¸Šä¸‹æ–‡ + æ·±åº¦æ¨ç† | Claude Opus 4.6ï¼ˆ1M betaï¼‰ã€Gemini 3 Pro |
| ç¼–ç  + æ™ºèƒ½ä½“æ‰§è¡Œ | GPT-5.3 Codexã€Claude Opus 4.6ã€MiniMax M2.5 |
| é«˜æ€§ä»·æ¯”ç¼–ç  | Gemini 3 Flashã€Sonnet 4.6ã€GLM-5ã€MiniMax M2.5 |
| å¿«é€Ÿè¿­ä»£ / å‰ç«¯å¼€å‘ | GPT-5.3 Codex Sparkã€Kimi K2.5ï¼ˆè§†è§‰ç¼–ç ï¼‰ |
| å¼€æº / è‡ªéƒ¨ç½² | GLM-5ã€Kimi K2.5ã€MiniMax M2.5 |
| æ–‡æ¡£ / OCR / å¤šæ¨¡æ€ | Kimi K2.5ã€Gemini 3 ç³»åˆ— |

## è¯´æ˜

- å®šä»·å’Œé…é¢éšæ—¶å¯èƒ½å˜åŠ¨ï¼Œè¯·ä»¥å®˜æ–¹æ–‡æ¡£ä¸ºå‡†ã€‚
- åŸºå‡†æµ‹è¯•åˆ†æ•°å› è¯„ä¼°è®¾ç½®è€Œå¼‚ï¼ŒåŒ…æ‹¬ pass@k è®¾ç½®ã€å·¥å…·å¯ç”¨æ€§å’Œæ€è€ƒé¢„ç®—çº§åˆ«ã€‚
- ç”¨æˆ·è¯„ä»·æ¥æºäº Redditã€Hacker Newsã€çŸ¥ä¹ã€V2EX å’Œæ˜é‡‘ â€” å‡ä¸ºä¸»è§‚ä¸ªäººä½“éªŒï¼Œä¸ä¸€å®šå…·æœ‰æ™®éä»£è¡¨æ€§ã€‚

---

<p align="center">
  <sub>Maintained by <b>Mingxu Zhang</b> & <b>Zheng Gong</b></sub>
</p>
