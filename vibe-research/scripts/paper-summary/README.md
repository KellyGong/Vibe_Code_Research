<h1 align="center">ğŸ“ Batch Paper Summary</h1>

<p align="center">
  <b>AI-powered batch PDF summarization with parallel workers</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/DeepSeek-API-8BC34A?logo=openai" alt="DeepSeek"/>
  <img src="https://img.shields.io/badge/PyMuPDF-PDF_Parser-blue" alt="PyMuPDF"/>
  <img src="https://img.shields.io/badge/Parallel-Workers-orange" alt="Parallel"/>
</p>

---

<details open>
<summary><b>ğŸ‡ºğŸ‡¸ English</b></summary>

## What It Does

Reads PDF papers in bulk, extracts text content, and uses **DeepSeek API** to generate structured summaries for each paper â€” all with configurable parallel workers.

### Prerequisites

```bash
pip install PyMuPDF openai
```

### Configuration

```bash
export DEEPSEEK_API_KEY="your-api-key-here"
```

### Usage

```bash
python batch_summary.py --input-dirs ./downloads ./nature_pdfs --output-dir ./output --workers 10
```

| Argument | Description | Default |
|----------|-------------|---------|
| `--input-dirs` | One or more PDF directories **(required)** | â€” |
| `--output-dir` | Output directory for summaries | `./output` |
| `--workers` | Number of parallel workers | `10` |

### Output Files

```
output/
â”œâ”€â”€ paper_summaries.md    # Markdown formatted summaries
â””â”€â”€ paper_summaries.json  # JSON formatted summaries
```

### Summary Format

Each paper is summarized with the following structure:

```
1. Paper Title
2. Model Used (Diffusion / LLM / GNN / Transformer)
3. Data Type (molecule / protein / cell + representation method)
4. Method (training strategy, training datasets)
5. Downstream Tasks (task type + dataset + metrics)
6. Contributions / Problems Solved
7. Limitations
```

### How It Works

```
PDF files  â†’  PyMuPDF text extraction (first 30 pages)
           â†’  DeepSeek API analysis (parallel)
           â†’  Markdown + JSON output
```

### Tips

- **Workers**: Start with 10, increase if your API quota allows
- **Text limit**: Each PDF is truncated to ~60K characters (~15K tokens)
- **Resume**: Already-processed papers are included in the output; re-run is safe

</details>

---

<details>
<summary><b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡</b></summary>

## åŠŸèƒ½ç®€ä»‹

æ‰¹é‡è¯»å– PDF è®ºæ–‡ï¼Œæå–æ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨ **DeepSeek API** ä¸ºæ¯ç¯‡è®ºæ–‡ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ â€” æ”¯æŒå¯é…ç½®çš„å¹¶è¡Œ workersã€‚

### å®‰è£…ä¾èµ–

```bash
pip install PyMuPDF openai
```

### é…ç½®

```bash
export DEEPSEEK_API_KEY="ä½ çš„APIå¯†é’¥"
```

### ä½¿ç”¨æ–¹æ³•

```bash
python batch_summary.py --input-dirs ./downloads ./nature_pdfs --output-dir ./output --workers 10
```

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--input-dirs` | ä¸€ä¸ªæˆ–å¤šä¸ªPDFç›®å½• **ï¼ˆå¿…å¡«ï¼‰** | â€” |
| `--output-dir` | æ‘˜è¦è¾“å‡ºç›®å½• | `./output` |
| `--workers` | å¹¶è¡Œ worker æ•°é‡ | `10` |

### è¾“å‡ºæ–‡ä»¶

```
output/
â”œâ”€â”€ paper_summaries.md    # Markdown æ ¼å¼æ‘˜è¦
â””â”€â”€ paper_summaries.json  # JSON æ ¼å¼æ‘˜è¦
```

### æ‘˜è¦æ ¼å¼

æ¯ç¯‡è®ºæ–‡æŒ‰ä»¥ä¸‹ç»“æ„æ€»ç»“ï¼š

```
1. æ–‡ç« é¢˜ç›®
2. ä½¿ç”¨æ¨¡å‹ï¼ˆDiffusion / LLM / GNN / Transformerï¼‰
3. æ•°æ®ç±»å‹ï¼ˆåˆ†å­ / è›‹ç™½è´¨ / ç»†èƒ + è¡¨å¾æ–¹æ³•ï¼‰
4. æ–¹æ³•ï¼ˆè®­ç»ƒç­–ç•¥ã€è®­ç»ƒæ•°æ®é›†ï¼‰
5. ä¸‹æ¸¸ä»»åŠ¡ï¼ˆä»»åŠ¡ç±»å‹ + æ•°æ®é›† + æŒ‡æ ‡ï¼‰
6. è´¡çŒ® / è§£å†³çš„é—®é¢˜
7. å±€é™æ€§
```

### å·¥ä½œåŸç†

```
PDF æ–‡ä»¶  â†’  PyMuPDF æ–‡æœ¬æå–ï¼ˆå‰30é¡µï¼‰
          â†’  DeepSeek API åˆ†æï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
          â†’  Markdown + JSON è¾“å‡º
```

### ä½¿ç”¨å»ºè®®

- **Worker æ•°é‡**ï¼šå»ºè®®ä» 10 å¼€å§‹ï¼Œæ ¹æ® API é…é¢é€‚å½“å¢åŠ 
- **æ–‡æœ¬é™åˆ¶**ï¼šæ¯ä¸ª PDF æˆªå–çº¦ 60K å­—ç¬¦ï¼ˆçº¦ 15K tokensï¼‰
- **æ–­ç‚¹ç»­ä¼ **ï¼šé‡å¤è¿è¡Œå®‰å…¨ï¼Œå·²å¤„ç†çš„è®ºæ–‡ä¼šä¿ç•™åœ¨è¾“å‡ºä¸­

</details>
