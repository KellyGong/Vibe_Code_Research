<h1 align="center">ğŸ“¥ Paper Download Scripts</h1>

<p align="center">
  <b>Multi-source paper acquisition with cascading retry</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Nature-Cookie_Auth-4CAF50" alt="Nature"/>
  <img src="https://img.shields.io/badge/arXiv-Direct-B31B1B" alt="arXiv"/>
  <img src="https://img.shields.io/badge/Semantic_Scholar-API-1976D2" alt="S2"/>
  <img src="https://img.shields.io/badge/Unpaywall-Open_Access-yellow" alt="Unpaywall"/>
  <img src="https://img.shields.io/badge/PMC-PubMed_Central-blue" alt="PMC"/>
</p>

---

<details open>
<summary><b>ğŸ‡ºğŸ‡¸ English</b></summary>

## Overview

Three scripts that work together as a **download cascade**:

```
download_nature.py  â†’  download_missing.py  â†’  download_retry.py
     Nature PDFs         Other sources           Retry failed ones
```

### Prerequisites

```bash
pip install requests pandas tqdm
```

---

### 1. `download_nature.py` â€” Nature Journal Downloader

Downloads papers from Nature journals using browser cookie authentication.

```bash
python download_nature.py --csv papers.csv --output ./nature_pdfs --cookies cookies.json
```

| Argument | Description | Default |
|----------|-------------|---------|
| `--csv` | CSV file with paper URLs **(required)** | â€” |
| `--output` | Output directory | `./nature_pdfs` |
| `--cookies` | Cookie JSON file | `./cookies.json` |

**Cookie Setup:**

1. Install **Cookie-Editor** Chrome extension
2. Visit `https://www.nature.com` and log in with your institution
3. Click Cookie-Editor â†’ **Export as JSON**
4. Save the exported content to `cookies.json`

**Features:**
- Auto-detects Nature article URLs from CSV
- Validates downloaded PDFs (checks Content-Type + file header)
- Tracks progress with `downloaded.txt` / `failed.txt`
- Retries up to 3 times per paper

---

### 2. `download_missing.py` â€” Multi-source Downloader

Downloads non-Nature papers from multiple sources with multi-threading.

```bash
python download_missing.py --csv papers.csv --output ./downloads --proxy http://127.0.0.1:7890
```

| Argument | Description | Default |
|----------|-------------|---------|
| `--csv` | CSV file with paper info **(required)** | â€” |
| `--output` | Output directory | `./downloads` |
| `--proxy` | HTTP proxy URL | _(none)_ |

**Download Strategy (in order):**
1. Direct PDF link
2. arXiv ID extraction â†’ PDF
3. Semantic Scholar API â†’ OpenAccess PDF
4. DOI-based URL conversion

**Features:**
- 8 parallel download threads
- Auto venue abbreviation (NeurIPS, ICML, ACL, ...)
- Skips already-downloaded files
- Saves failures to `download_failed.txt`

---

### 3. `download_retry.py` â€” Retry with Alternative Sources

Retries failed downloads using academic open-access APIs.

```bash
python download_retry.py --failed-file download_failed.txt --output ./downloads --proxy http://127.0.0.1:7890
```

| Argument | Description | Default |
|----------|-------------|---------|
| `--failed-file` | Failed papers list **(required)** | â€” |
| `--output` | Output directory | `./downloads` |
| `--proxy` | HTTP proxy URL | _(none)_ |

**Sources:**
- **arXiv API** â€” title-based search
- **Unpaywall** â€” via Crossref DOI lookup
- **PubMed Central** â€” open access repository

**Features:**
- 4 parallel threads
- Validates file size (minimum 5KB)
- Outputs remaining failures to `download_still_failed.txt`

</details>

---

<details>
<summary><b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡</b></summary>

## æ¦‚è¿°

ä¸‰ä¸ªè„šæœ¬ç»„æˆ **çº§è”ä¸‹è½½æµæ°´çº¿**ï¼š

```
download_nature.py  â†’  download_missing.py  â†’  download_retry.py
    Nature è®ºæ–‡           å…¶ä»–æ¥æºè®ºæ–‡            é‡è¯•å¤±è´¥çš„è®ºæ–‡
```

### å®‰è£…ä¾èµ–

```bash
pip install requests pandas tqdm
```

---

### 1. `download_nature.py` â€” Nature æœŸåˆŠä¸‹è½½å™¨

ä½¿ç”¨æµè§ˆå™¨ Cookie è®¤è¯ä¸‹è½½ Nature ç³»åˆ—è®ºæ–‡ã€‚

```bash
python download_nature.py --csv papers.csv --output ./nature_pdfs --cookies cookies.json
```

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--csv` | åŒ…å«è®ºæ–‡URLçš„CSVæ–‡ä»¶ **ï¼ˆå¿…å¡«ï¼‰** | â€” |
| `--output` | è¾“å‡ºç›®å½• | `./nature_pdfs` |
| `--cookies` | Cookie JSON æ–‡ä»¶ | `./cookies.json` |

**Cookie è·å–æ–¹æ³•ï¼š**

1. å®‰è£… Chrome æ‰©å±• **Cookie-Editor**
2. è®¿é—® `https://www.nature.com` å¹¶é€šè¿‡æœºæ„ç™»å½•
3. ç‚¹å‡» Cookie-Editor â†’ **Export as JSON**
4. å°†å¯¼å‡ºå†…å®¹ä¿å­˜ä¸º `cookies.json`

**ç‰¹æ€§ï¼š**
- è‡ªåŠ¨ä»CSVä¸­è¯†åˆ« Nature æ–‡ç«  URL
- éªŒè¯ä¸‹è½½çš„PDFï¼ˆæ£€æŸ¥ Content-Type + æ–‡ä»¶å¤´ï¼‰
- ç”¨ `downloaded.txt` / `failed.txt` è¿½è¸ªè¿›åº¦
- æ¯ç¯‡è®ºæ–‡æœ€å¤šé‡è¯•3æ¬¡

---

### 2. `download_missing.py` â€” å¤šæºä¸‹è½½å™¨

å¤šçº¿ç¨‹ä»å¤šä¸ªæ¥æºä¸‹è½½é Nature è®ºæ–‡ã€‚

```bash
python download_missing.py --csv papers.csv --output ./downloads --proxy http://127.0.0.1:7890
```

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--csv` | è®ºæ–‡ä¿¡æ¯CSVæ–‡ä»¶ **ï¼ˆå¿…å¡«ï¼‰** | â€” |
| `--output` | è¾“å‡ºç›®å½• | `./downloads` |
| `--proxy` | HTTPä»£ç†åœ°å€ | _(æ— )_ |

**ä¸‹è½½ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š**
1. ç›´æ¥ PDF é“¾æ¥
2. æå– arXiv ID â†’ ä¸‹è½½ PDF
3. Semantic Scholar API â†’ OpenAccess PDF
4. DOI é“¾æ¥è½¬æ¢

**ç‰¹æ€§ï¼š**
- 8 çº¿ç¨‹å¹¶è¡Œä¸‹è½½
- è‡ªåŠ¨è¯†åˆ«ä¼šè®®/æœŸåˆŠç¼©å†™ï¼ˆNeurIPS, ICML, ACL...ï¼‰
- è·³è¿‡å·²ä¸‹è½½æ–‡ä»¶
- å¤±è´¥è®°å½•ä¿å­˜è‡³ `download_failed.txt`

---

### 3. `download_retry.py` â€” å¤šæºé‡è¯•ä¸‹è½½

ä½¿ç”¨å­¦æœ¯å¼€æ”¾è·å– API é‡è¯•ä¸‹è½½å¤±è´¥çš„è®ºæ–‡ã€‚

```bash
python download_retry.py --failed-file download_failed.txt --output ./downloads --proxy http://127.0.0.1:7890
```

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--failed-file` | å¤±è´¥è®ºæ–‡åˆ—è¡¨ **ï¼ˆå¿…å¡«ï¼‰** | â€” |
| `--output` | è¾“å‡ºç›®å½• | `./downloads` |
| `--proxy` | HTTPä»£ç†åœ°å€ | _(æ— )_ |

**æ•°æ®æºï¼š**
- **arXiv API** â€” æŒ‰æ ‡é¢˜æœç´¢
- **Unpaywall** â€” é€šè¿‡ Crossref è·å– DOI åæŸ¥è¯¢
- **PubMed Central** â€” å¼€æ”¾è·å–èµ„æºåº“

**ç‰¹æ€§ï¼š**
- 4 çº¿ç¨‹å¹¶è¡Œ
- éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆæœ€å° 5KBï¼‰
- ä»å¤±è´¥çš„è®°å½•ä¿å­˜è‡³ `download_still_failed.txt`

</details>
