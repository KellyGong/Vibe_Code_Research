<h1 align="center">ğŸ”¬ Vibe Research Scripts</h1>

<p align="center">
  <b>AI-Powered Academic Research Toolkit</b><br>
  <sub>From literature search to batch summarization â€” everything you need for writing a survey.</sub>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue?logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/DeepSeek-API-green?logo=openai&logoColor=white" alt="DeepSeek"/>
  <img src="https://img.shields.io/badge/Streamlit-UI-FF4B4B?logo=streamlit&logoColor=white" alt="Streamlit"/>
  <img src="https://img.shields.io/badge/License-MIT-yellow" alt="License"/>
</p>

---

<details open>
<summary><b>ğŸ‡ºğŸ‡¸ English</b></summary>

## Overview

This module provides a **complete pipeline** for survey literature review:

```
ğŸ” Search  â†’  ğŸ“¥ Download  â†’  ğŸ“ Summarize  â†’  ğŸ—‚ï¸ Classify & Organize
```

## Directory Structure

```
scripts/
â”œâ”€â”€ ğŸ“‚ paper-search/          # Literature retrieval
â”‚   â””â”€â”€ paper_search.py        # Streamlit app: Nature + Semantic Scholar + translation
â”‚
â”œâ”€â”€ ğŸ“‚ paper-download/         # PDF acquisition
â”‚   â”œâ”€â”€ download_nature.py     # Nature journals (cookie auth)
â”‚   â”œâ”€â”€ download_missing.py    # Multi-source (arXiv, S2, DOI)
â”‚   â””â”€â”€ download_retry.py      # Retry via Unpaywall, PMC
â”‚
â”œâ”€â”€ ğŸ“‚ paper-summary/          # AI summarization
â”‚   â””â”€â”€ batch_summary.py       # DeepSeek batch summary (parallel)
â”‚
â””â”€â”€ ğŸ“‚ utils/                  # Advanced tools
    â”œâ”€â”€ pdf_constructor.py     # Survey outline classification + mindmaps
    â”œâ”€â”€ pdf_reader.py          # Detailed structured summaries
    â”œâ”€â”€ mindmap_viewer.py      # Flask web UI for classification
    â”œâ”€â”€ validate_pdfs.py       # PDF quality validation
    â”œâ”€â”€ analyze_coverage.py    # Paper coverage analysis
    â”œâ”€â”€ split_by_journal.py    # Split summaries by venue
    â”œâ”€â”€ rename_pdfs.py         # Standardize PDF filenames
    â””â”€â”€ run_pipeline.sh        # One-click automation
```

## Quick Start

### 1. Install Dependencies

```bash
pip install streamlit requests pandas beautifulsoup4 openai PyMuPDF tqdm flask pyyaml
```

### 2. Set API Key

```bash
export DEEPSEEK_API_KEY="your-api-key-here"
```

### 3. Launch Search Tool

```bash
streamlit run scripts/paper-search/paper_search.py
```

## Complete Workflow

| Step | Command | Output |
|------|---------|--------|
| **1. Search** | `streamlit run scripts/paper-search/paper_search.py` | `papers.csv` |
| **2. Download Nature** | `python scripts/paper-download/download_nature.py --csv papers.csv` | PDFs in `nature_pdfs/` |
| **3. Download Others** | `python scripts/paper-download/download_missing.py --csv papers.csv` | PDFs in `downloads/` |
| **4. Retry Failed** | `python scripts/paper-download/download_retry.py --failed-file download_failed.txt` | More PDFs |
| **5. Validate** | `python scripts/utils/validate_pdfs.py --input-dir ./downloads` | Quality report |
| **6. Summarize** | `python scripts/paper-summary/batch_summary.py --input-dirs ./downloads ./nature_pdfs` | Markdown + JSON |
| **7. Classify** | `python scripts/utils/pdf_constructor.py --batch --merge` | Mindmaps |
| **8. Visualize** | `python scripts/utils/mindmap_viewer.py` | Web UI at `:5000` |

## Module Details

Each subdirectory has its own README with detailed usage instructions:

- [**Paper Search** â†’](./scripts/paper-search/README.md) Streamlit web app for multi-source literature search
- [**Paper Download** â†’](./scripts/paper-download/README.md) Cascading download scripts with retry logic
- [**Paper Summary** â†’](./scripts/paper-summary/README.md) Batch AI summarization with parallel workers
- [**Utilities** â†’](./scripts/utils/README.md) Classification, validation, visualization tools

</details>

---

<details>
<summary><b>ğŸ‡¨ğŸ‡³ ä¸­æ–‡</b></summary>

## æ¦‚è¿°

æœ¬æ¨¡å—æä¾›äº† **å®Œæ•´çš„æ–‡çŒ®ç»¼è¿°æµæ°´çº¿**ï¼š

```
ğŸ” æ£€ç´¢è®ºæ–‡  â†’  ğŸ“¥ ä¸‹è½½PDF  â†’  ğŸ“ æ‰¹é‡æ‘˜è¦  â†’  ğŸ—‚ï¸ åˆ†ç±»æ•´ç†
```

## ç›®å½•ç»“æ„

```
scripts/
â”œâ”€â”€ ğŸ“‚ paper-search/          # æ–‡çŒ®æ£€ç´¢
â”‚   â””â”€â”€ paper_search.py        # Streamlitåº”ç”¨ï¼šNature + Semantic Scholar + ç¿»è¯‘
â”‚
â”œâ”€â”€ ğŸ“‚ paper-download/         # PDFä¸‹è½½
â”‚   â”œâ”€â”€ download_nature.py     # NatureæœŸåˆŠï¼ˆCookieè®¤è¯ï¼‰
â”‚   â”œâ”€â”€ download_missing.py    # å¤šæºä¸‹è½½ï¼ˆarXiv, S2, DOIï¼‰
â”‚   â””â”€â”€ download_retry.py      # é‡è¯•ä¸‹è½½ï¼ˆUnpaywall, PMCï¼‰
â”‚
â”œâ”€â”€ ğŸ“‚ paper-summary/          # AIæ‘˜è¦
â”‚   â””â”€â”€ batch_summary.py       # DeepSeekæ‰¹é‡æ‘˜è¦ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
â”‚
â””â”€â”€ ğŸ“‚ utils/                  # é«˜çº§å·¥å…·
    â”œâ”€â”€ pdf_constructor.py     # æŒ‰Surveyå¤§çº²åˆ†ç±» + ç”Ÿæˆæ€ç»´å¯¼å›¾
    â”œâ”€â”€ pdf_reader.py          # è¯¦ç»†ç»“æ„åŒ–æ‘˜è¦
    â”œâ”€â”€ mindmap_viewer.py      # Flask Webç•Œé¢ç®¡ç†åˆ†ç±»
    â”œâ”€â”€ validate_pdfs.py       # PDFè´¨é‡éªŒè¯
    â”œâ”€â”€ analyze_coverage.py    # è®ºæ–‡è¦†ç›–ç‡åˆ†æ
    â”œâ”€â”€ split_by_journal.py    # æŒ‰æœŸåˆŠ/ä¼šè®®æ‹†åˆ†æ‘˜è¦
    â”œâ”€â”€ rename_pdfs.py         # ç»Ÿä¸€PDFæ–‡ä»¶å‘½å
    â””â”€â”€ run_pipeline.sh        # ä¸€é”®è‡ªåŠ¨åŒ–è„šæœ¬
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install streamlit requests pandas beautifulsoup4 openai PyMuPDF tqdm flask pyyaml
```

### 2. é…ç½® API Key

```bash
export DEEPSEEK_API_KEY="ä½ çš„APIå¯†é’¥"
```

### 3. å¯åŠ¨æ£€ç´¢å·¥å…·

```bash
streamlit run scripts/paper-search/paper_search.py
```

## å®Œæ•´å·¥ä½œæµ

| æ­¥éª¤ | å‘½ä»¤ | è¾“å‡º |
|------|------|------|
| **1. æ£€ç´¢** | `streamlit run scripts/paper-search/paper_search.py` | `papers.csv` |
| **2. ä¸‹è½½Nature** | `python scripts/paper-download/download_nature.py --csv papers.csv` | `nature_pdfs/` ä¸­çš„PDF |
| **3. ä¸‹è½½å…¶ä»–** | `python scripts/paper-download/download_missing.py --csv papers.csv` | `downloads/` ä¸­çš„PDF |
| **4. é‡è¯•å¤±è´¥** | `python scripts/paper-download/download_retry.py --failed-file download_failed.txt` | æ›´å¤šPDF |
| **5. è´¨é‡éªŒè¯** | `python scripts/utils/validate_pdfs.py --input-dir ./downloads` | éªŒè¯æŠ¥å‘Š |
| **6. æ‰¹é‡æ‘˜è¦** | `python scripts/paper-summary/batch_summary.py --input-dirs ./downloads ./nature_pdfs` | Markdown + JSON |
| **7. åˆ†ç±»æ•´ç†** | `python scripts/utils/pdf_constructor.py --batch --merge` | æ€ç»´å¯¼å›¾ |
| **8. å¯è§†åŒ–** | `python scripts/utils/mindmap_viewer.py` | Webç•Œé¢ `:5000` |

## å„æ¨¡å—è¯¦æƒ…

æ¯ä¸ªå­ç›®å½•éƒ½æœ‰ç‹¬ç«‹çš„ README æ–‡æ¡£ï¼š

- [**æ–‡çŒ®æ£€ç´¢** â†’](./scripts/paper-search/README.md) Streamlitå¤šæºæ–‡çŒ®æ£€ç´¢å·¥å…·
- [**è®ºæ–‡ä¸‹è½½** â†’](./scripts/paper-download/README.md) çº§è”ä¸‹è½½ä¸é‡è¯•è„šæœ¬
- [**æ‰¹é‡æ‘˜è¦** â†’](./scripts/paper-summary/README.md) DeepSeekå¹¶è¡ŒAIæ‘˜è¦
- [**å·¥å…·é›†** â†’](./scripts/utils/README.md) åˆ†ç±»ã€éªŒè¯ã€å¯è§†åŒ–å·¥å…·

</details>

---

<p align="center"><sub>Maintained by <b>Mingxu Zhang</b> & <b>Zheng Gong</b></sub></p>
